{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/02_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4991e-9de8-4418-8c5c-6d904fb9b4de",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "#### NumPy\n",
    "\n",
    "```python\n",
    "np.random.normal(size=(1,))  # scalar\n",
    "np.random.normal(size=(3,))  # vector\n",
    "np.random.normal(size=(3, 3))  # matrix\n",
    "```\n",
    "\n",
    "#### [TensorFlow](https://www.tensorflow.org/guide/tensor)\n",
    "\n",
    "```python\n",
    "tf.random.normal(shape=(1,))  # scalar\n",
    "tf.random.normal(shape=(3,))  # vector\n",
    "tf.random.normal(shape=(3, 3))  # matrix\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b87f7b-eb97-4738-a6f9-fe76997c5b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad4c1da7-4b22-40d6-95ef-2f6a2a628dfd",
   "metadata": {},
   "source": [
    "## Data pipelines\n",
    "\n",
    "The data pipeline can be useful:\n",
    "\n",
    "- When the data does not fit in memory.\n",
    "- When the data requires pre-processing.\n",
    "- To efficiently use hardware.\n",
    "\n",
    "The steps can include:\n",
    "\n",
    "- Extract e.g., read data from memory / storage.\n",
    "- Transform e.g., pre-processing, batching, shuffling.\n",
    "- Load e.g., transfer to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc9f84-c149-4142-b6d4-68616b19f312",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "[Keras](https://keras.io/api/data_loading/) models accept three types of inputs:\n",
    "\n",
    "- [NumPy arrays](https://www.tensorflow.org/guide/data#consuming_numpy_arrays)\n",
    "    - Suitable for when the data fits in memory.\n",
    "- [TensorFlow Dataset objects](https://www.tensorflow.org/guide/data#dataset_structure)\n",
    "    - Suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n",
    "- [Python generators](https://www.tensorflow.org/guide/data#consuming_python_generators)\n",
    "    - Suitable for custom processing yielding batches of data (subclasses of `tf.keras.utils.Sequence` class).\n",
    "\n",
    "If you have a large dataset and you are training on GPU(s), consider using `Dataset` objects, since they will take care of performance-critical details, such as:\n",
    "\n",
    "- Asynchronously preprocessing your data on CPU while your GPU is busy, and buffering it into a queue.\n",
    "- Prefetching data on GPU memory so it's immediately available when the GPU has finished processing the previous batch, so you can reach full GPU utilization.\n",
    "\n",
    "Keras features a range of utilities to help you turn raw data on disk into a Dataset:\n",
    "\n",
    "- [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) turns image files sorted into class-specific folders into a labeled dataset of image tensors.\n",
    "- [`tf.keras.utils.text_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory) does the same for text files.\n",
    "- [`tf.keras.utils.timeseries_dataset_from_array`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array) creates a dataset of sliding windows over a timeseries provided as array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c69061-254f-4440-9f6a-aa7e8cbae26f",
   "metadata": {},
   "source": [
    "\"step fusing\"\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimiser,\n",
    "    loss,\n",
    "    steps_per_execution=32  # this step\n",
    ")\n",
    "model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a1720-77d5-4d44-973b-60dd2c2a1da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5810e-1086-439c-b2ae-5b335bea9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model for 1 epoch from Numpy data\n",
    "# batch_size = 64\n",
    "# print(\"Fit on NumPy data\")\n",
    "# history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)\n",
    "\n",
    "# # Train the model for 1 epoch using a dataset\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "# print(\"Fit on Dataset\")\n",
    "# history = model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d86bf7-26f5-40a1-996b-9fadb6c8cd28",
   "metadata": {},
   "source": [
    "### [Map](https://www.tensorflow.org/guide/data#preprocessing_data)\n",
    "\n",
    "Map a preprocessing function to a dataset.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.map(function)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643aa15-7bb3-4885-9889-f218ea1ae56b",
   "metadata": {},
   "source": [
    "### [Batch](https://www.tensorflow.org/guide/data#batching_dataset_elements)\n",
    "\n",
    "Split the data into batches.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.batch(batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98021ef-a4e6-4aa8-a475-98bccc0d59bb",
   "metadata": {},
   "source": [
    "There are range of ways to [improve the performance](https://www.tensorflow.org/guide/data_performance) of the data pipeline.\n",
    "\n",
    "In these examples, using `tf.data.AUTOTUNE` leaves the decision to TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5997c7-740e-4537-9324-78bf44945549",
   "metadata": {},
   "source": [
    "(cache_prefetch)=\n",
    "### [Dataset caching](https://www.tensorflow.org/guide/data_performance#caching)\n",
    "\n",
    "Cache the data after the first iteration through it. The data can be cached to either memory or a local file.\n",
    "\n",
    "This can improve performance when:\n",
    "\n",
    "- The data is the same each iteration.\n",
    "- The data is read from a remote distributed filesystem.\n",
    "- The data is I/O (input/output) bound and will fit in memory.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc418c3-02bb-411f-a3e4-66881fd13ff4",
   "metadata": {},
   "source": [
    "### [Prefetch data](https://www.tensorflow.org/guide/data_performance#prefetching)\n",
    "\n",
    "Prefect the next batch to save time waiting for it.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9acb0-d20b-48ab-a204-6473c50931ed",
   "metadata": {},
   "source": [
    "### [Parallel data extraction](https://www.tensorflow.org/guide/data_performance#parallelizing_data_extraction)\n",
    "\n",
    "Extract the data in parallel.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.interleave(\n",
    "    build_dataset, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c41aa-b850-46a3-a910-27dce98146ce",
   "metadata": {},
   "source": [
    "###  [Parallel data transformation](https://www.tensorflow.org/guide/data_performance#parallelizing_data_transformation)\n",
    "\n",
    "Pre-process your data in parallel.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.map(\n",
    "    function, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e2947-d742-49be-a778-6f55709063c1",
   "metadata": {},
   "source": [
    "### [Vectorise mapping](https://www.tensorflow.org/guide/data_performance#vectorizing_mapping)\n",
    "\n",
    "Batch _before_ mapping, to vectorise a function.\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "```python\n",
    "dataset.batch(256).map(function)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2515bb-2d97-4621-b6f6-ae3586969ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87a945-535b-4041-b4d4-b520ae971bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fef8cd7e-1841-45e6-85b0-494ada8c881b",
   "metadata": {},
   "source": [
    "jit compile\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimiser,\n",
    "    loss,\n",
    "    jit_compile=True  # this step\n",
    ")\n",
    "model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c2c5d-11cc-47c3-895d-ad82b8c3f940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd2169-abea-4ee2-899e-e26fcbf91e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ec18c1-3dad-4d18-9830-55acd84397e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "- Tokenization of string data, followed by token indexing.\n",
    "- Feature normalization.\n",
    "- Rescaling the data to small values (in general, input values to a neural network should be close to zero -- typically we expect either data with zero-mean and unit-variance, or data in the [0, 1] range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17d4f1-a78a-42cb-9630-3d5f0dd7a6ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0da989-7664-49f9-9b5e-f9321fb81670",
   "metadata": {},
   "source": [
    "## [Mixed precision](https://www.tensorflow.org/guide/mixed_precision)\n",
    "\n",
    "...\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_policy('mixed_float16')\n",
    "\n",
    "with distribution_strategy.scopy():\n",
    "    model = build_model()\n",
    "    model.compile(optimiser, loss)\n",
    "    model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ee263-d591-4417-8c86-5b26a843b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea9e50-8cd8-4b1e-b1a9-a6c84588fc76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2d7db6-9738-4a79-b501-955e520f2118",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64f1798-eb46-4759-b023-8dd649f74c40",
   "metadata": {},
   "source": [
    "- datasets\n",
    "- data centric AI hub videos\n",
    "- efficient feeding of data into GPUs\n",
    "- pipelines for large data I/O into GPUs using compression/decompression, Ray datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172576cd-85b0-40f4-8705-139a543e3a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33379cf8-83ff-4970-86bd-f663f9ac086e",
   "metadata": {},
   "source": [
    "## TensorFlow Datasets\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5416411-b3f6-4919-8187-650f7c222491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0dca36-204b-43b9-a17d-2cb93d3aab16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a07bd4-5506-42fa-98c9-baa3ffd81a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9160d4f8-3d05-4329-8e8f-17cc795a5ef6",
   "metadata": {},
   "source": [
    "(data_augmentation)=\n",
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cdd81d-97b0-414b-91c2-c2fe1e89867c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec5b9649-dfb3-4d66-bdb7-a565a9bdc3be",
   "metadata": {},
   "source": [
    "### Synthetic data\n",
    "\n",
    "...\n",
    "\n",
    "- [NVIDIA Replicator Composer](https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/tutorial_replicator_composer.html#replicator-composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c515783-b33e-448b-8b7d-2a264dd5bdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f47a8-9ad1-4dba-8577-c5b394ee3b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f13dcc-ae37-4518-8ff1-fad3c30dc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1390c-7a87-4fe8-a640-58b0164bd58a",
   "metadata": {},
   "source": [
    "Check whether you have a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e0de7f-6c5e-4272-b109-bac76ecd0e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34152b35-1cbe-4b3d-96f0-f5a47f523c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <data>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _Use a data pipeline._\n",
    "- [x] _Optimise the data pipeline with caching, prefetching, parallel extraction, parallel preprocessing, and vectorised mapping._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Do data processing as part of the model to increase portability and reproducibility.\n",
    "- Analyse data pipeline performance with [TensorBoard Profiler](https://www.tensorflow.org/guide/data_performance_analysis).\n",
    "- Use sparse tensors when there are many zeros / np.nans (e.g., [TensorFlow](https://www.tensorflow.org/guide/sparse_tensor)).\n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- ...\n",
    " \n",
    "### Resources\n",
    "\n",
    "#### General\n",
    "\n",
    "- [Papers with code - Datasets](https://paperswithcode.com/datasets)\n",
    "- [HuggingFace - Datasets](https://huggingface.co/datasets)\n",
    "- [Google research datasets](https://ai.google/tools/datasets/)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com/)\n",
    "- [Google Cloud public datasets](https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset&pli=1)\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "- [TensorFlow official datasets](https://www.tensorflow.org/datasets)\n",
    "\n",
    "#### PyTorch\n",
    "\n",
    "- [Torch Vision Datasets](https://pytorch.org/vision/stable/datasets.html)\n",
    "- [Torch Text Datasets](https://pytorch.org/text/stable/datasets.html)\n",
    "- [Torch Audio Datasets](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c3e08-05b5-431f-b842-82ffe49b99c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
