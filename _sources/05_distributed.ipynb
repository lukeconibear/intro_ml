{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/05_distributed.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8aa72b-89d2-47e8-9dae-d6eff282617a",
   "metadata": {},
   "source": [
    "Distributing training over multiple devices generally uses either:\n",
    "\n",
    "- [Data parallelism](https://developers.google.com/machine-learning/glossary/#data-parallelism)\n",
    "    - Single model copied to multiple devices.\n",
    "    - Split data over multiple devices.\n",
    "    - Useful for big data.\n",
    "- [Model parallelism](https://developers.google.com/machine-learning/glossary/#model-parallelism)\n",
    "    - Split model over multiple devices.\n",
    "    - Single data copied to multiple devices.\n",
    "    - Useful for big models.\n",
    "    \n",
    "This lesson focuses on data parallelism.\n",
    "\n",
    "The distributed training can also be:\n",
    "\n",
    "- Synchronous, where the training steps are synced across the workers.\n",
    "- Asynchronous, where the training steps are not strictly synced across the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d8a2d-2e9a-4fb5-ac9e-1d5839a6d212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9192221c-7f41-4b0d-abc5-2d2045db01e5",
   "metadata": {},
   "source": [
    "## [TensorFlow](https://www.tensorflow.org/guide/distributed_training)\n",
    "\n",
    "You can use `tf.distribute.Strategy` to distribute models and training over multiple machines with minimal code changes.\n",
    "\n",
    "For example, there is [MirroredStrategy](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy) for multiple replicas on one machine and [MultiWorkerMirroredStrategy](https://www.tensorflow.org/guide/distributed_training#multiworkermirroredstrategy) for synchronous training of multiple workers across many machines.\n",
    "\n",
    "Within the strategy scope, you build a compiled the model.\n",
    "\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_compiled_model()\n",
    "    \n",
    "model.fit(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de49dc9b-be8a-4260-a8cb-e83fa752f8bd",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "For multiple workers, you'll need to set the [`TF_CONFIG`](https://www.tensorflow.org/guide/distributed_training#setting_up_the_tf_config_environment_variable). There is an example [here](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bb0f1-b416-4cfb-9b36-c004a67385db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = {\n",
    "    \"cluster\": {\"worker\": [\"localhost:12345\", \"localhost:23456\"]},\n",
    "    \"task\": {\"type\": \"worker\", \"index\": 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef57b801-e35d-4c0b-b5a0-d7ebedae1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d416480-1763-42b0-8005-ac629f47e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d443e-722f-466e-b832-871739f944d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0389bc77-86a7-4cf1-ac4d-3ebc0ff9bbcc",
   "metadata": {},
   "source": [
    "An [example for MNIST](https://www.tensorflow.org/tutorials/distribute/keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b4a3ba-9430-480f-b0be-23a7f750f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:09:09.661248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-24 18:09:09.661266: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63233852-b12a-4ec2-a652-633cd4271b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compiled_model():\n",
    "    inputs = tf.keras.Input(shape=(784,))\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b800ca-71c6-4c81-955a-95abbaaaa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    batch_size = 32 * strategy.num_replicas_in_sync\n",
    "    num_val_samples = 10000\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    y_train = y_train.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    # reserve num_val_samples samples for validation\n",
    "    x_val = x_train[-num_val_samples:]\n",
    "    y_val = y_train[-num_val_samples:]\n",
    "    x_train = x_train[:-num_val_samples]\n",
    "    y_train = y_train[:-num_val_samples]\n",
    "    \n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36e547-3956-467c-8794-bd227d01e503",
   "metadata": {},
   "source": [
    "Create a MirroredStrategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad22a6a0-5c67-4b25-8862-7284d4d5613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:09:12.736716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-24 18:09:12.736737: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-24 18:09:12.736759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (UOL-LAP-5G6CZH3): /proc/driver/nvidia/version does not exist\n",
      "2022-03-24 18:09:12.736948: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc8a19c-3b38-4595-afc7-69ba573867e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904811db-234c-4e75-8a7a-38e055e97251",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25269241-0537-4156-951e-a38cd011bf01",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "The default [auto-sharding](https://www.tensorflow.org/api_docs/python/tf/data/experimental/AutoShardPolicy) by `FILE` can cause warning messages. Instead:\n",
    "\n",
    "- Either disable auto-sharding using: `tf.data.experimental.AutoShardPolicy.OFF`  \n",
    "- Or auto-shard by data: `tf.data.experimental.AutoShardPolicy.DATA`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf0159da-1e08-4b1d-bf6e-aed1d9b3ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "train_dataset = train_dataset.with_options(options)\n",
    "val_dataset = val_dataset.with_options(options)\n",
    "test_dataset = test_dataset.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530007f6-7cca-4f19-bd23-1646cf9e3594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:40:36.770383: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=2, validation_data=val_dataset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585351fa-c648-424e-b2c2-923582dc79ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.03628438338637352, 0.02810976840555668],\n",
       " 'sparse_categorical_accuracy': [0.9881200194358826, 0.990559995174408],\n",
       " 'val_loss': [0.09779918193817139, 0.10384755581617355],\n",
       " 'val_sparse_categorical_accuracy': [0.9761000275611877, 0.9758999943733215]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0326edd3-cf92-4f63-9e8f-b1f3f88638a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 871us/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0892195999622345, 0.9724000096321106]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3a4a7-84db-4227-a198-00a3ac70e3c1",
   "metadata": {},
   "source": [
    "Written up here:\n",
    "\n",
    "[`tensorflow_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/tensorflow_mnist_example.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcf15b-2495-40e1-983d-1a01e9a3f3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb32fc-bfa8-4c07-833a-5396b2669365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d07bcb0-83e6-43c8-a5af-0dac1b9648f7",
   "metadata": {},
   "source": [
    "## Fault tolerance\n",
    "\n",
    "Use Model Checkpointing (saw in the previous lesson) to be able to recover a model from a previous epoch if the training fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a29a7b-72dd-4a2d-af80-050d9b12cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = f\"{os.getcwd()}/models/checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4247cd-0437-485d-8573-4065b184bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return tf.keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd8693-4030-4377-8a31-9353ca16f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(epochs=1):\n",
    "    # Create a MirroredStrategy.\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    # Open a strategy scope and create/restore the model\n",
    "    with strategy.scope():\n",
    "        model = make_or_restore_model()\n",
    "\n",
    "    callbacks = [\n",
    "        # This callback saves a SavedModel every epoch\n",
    "        # We include the current epoch in the folder name.\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_dir + \"/checkpoint-{epoch}\", save_freq=\"epoch\"\n",
    "        )\n",
    "    ]\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_dataset,\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130ba34-677b-4174-99ff-2c25ee6e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running the first time creates the model\n",
    "# run_training(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a5a88-1c84-4e84-9823-efc99fbb02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calling the same function again will resume from where we left off\n",
    "# run_training(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e01106-113f-43d2-8bce-52b02245faf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04bc93ce-77d4-4c0c-a4c0-12f08ca0a9d9",
   "metadata": {},
   "source": [
    "### Dataset caching\n",
    "\n",
    "Add data caching to an example\n",
    "\n",
    "and\n",
    "\n",
    "### Prefetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3b9de-7403-4f18-a4da-721567b8e14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec6be9-0817-46b3-bc33-04bd394b72a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b29d0-5709-48be-9901-16722e4fa7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e178d-9b5d-4096-b522-b6b7801ad75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c24c725f-0aed-4b26-b2c0-6e02de0ad324",
   "metadata": {},
   "source": [
    "Examples of how to distribute deep learning on a High Performance Computer (HPC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e0511-23ec-4f5a-a866-228bae6fd60c",
   "metadata": {},
   "source": [
    "## Install Python environments\n",
    "\n",
    "First, install the Python environments for the required HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d909d3-abf8-4531-b680-33d8a7db48d7",
   "metadata": {},
   "source": [
    "## ARC4\n",
    "\n",
    "### Miniconda installer\n",
    "```bash\n",
    "# download miniconda (x86_64 for ARC4)\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    "# run miniconda, read terms, and set path\n",
    ". Miniconda3-latest-Linux-x86_64.sh\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "# clone - tensorflow 2.7.0 and ray\n",
    "conda env create --file tf_ray_arc4.yml\n",
    "\n",
    "# clone - pytorch 1.10 and ray\n",
    "module load gnu/8.3.0\n",
    "conda env create --file pytorch_ray_arc4.yml\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "# create new - tensorflow 2.7.0 and ray\n",
    "conda create -n tf_ray_arc4 -c conda-forge python==3.9.* cudatoolkit==11.2.* cudnn==8.1.*\n",
    "conda activate tf_ray_arc4\n",
    "pip install -U pip\n",
    "pip install tensorflow==2.7.0\n",
    "pip install -U ray\n",
    "pip install -U ray[tune]\n",
    "\n",
    "# create new - pytorch (1.10) and ray\n",
    "module load gnu/8.3.0\n",
    "conda create -n pytorch_ray_arc4 pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "conda activate pytorch_ray_arc4\n",
    "pip install -U ray\n",
    "pip install -U ray[tune]\n",
    "\n",
    "# create new - jax\n",
    "conda create -n jax python=3.8 cudatoolkit=11.2 cudatoolkit-dev=11.2 cudnn=8.2\n",
    "conda activate jax\n",
    "pip install -U jax\n",
    "pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b51ba4-6980-4d56-976f-5bffd854751d",
   "metadata": {},
   "source": [
    "## Bede\n",
    "\n",
    "### Miniconda installer\n",
    "```bash\n",
    "# Replace <project> with your project code\n",
    "export DIR=/nobackup/projects/<project>/$USER\n",
    "\n",
    "# download miniconda (ppc64le for Bede's hardware, not x86_64 as for ARC4)\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-ppc64le.sh\n",
    " \n",
    "# run miniconda\n",
    "sh Miniconda3-latest-Linux-ppc64le.sh -b -p $DIR/miniconda\n",
    "source miniconda/bin/activate\n",
    " \n",
    "# update conda and set channels\n",
    "conda update conda -y\n",
    "conda config --prepend channels conda-forge\n",
    "conda config --prepend channels https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\n",
    "conda config --prepend channels https://opence.mit.edu\n",
    "```\n",
    "\n",
    "This is what my `~/.condarc` ends up as:\n",
    "```bash\n",
    "channel_priority: flexible\n",
    "channels:\n",
    "  - https://opence.mit.edu\n",
    "  - https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "# clone - tensorflow 2.7.0 and ray\n",
    "conda env create --file tf_bede.yml\n",
    "\n",
    "# clone - pytorch 1.10 and ray\n",
    "conda env create --file pytorch_bede.yml\n",
    "\n",
    "# clone - pytorch 1.9.0, cuda 10.2, and pytorch_geometric 2.0.3\n",
    "module load gcc # require this for some of the libraries\n",
    "conda env create --file pytorch_geometric_bede.yml\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "# create an environment for pytorch\n",
    "conda create -n pytorch pytorch torchvision cudatoolkit=10.2\n",
    " \n",
    "# create an environment for tensorflow\n",
    "conda create -n tf tensorflow\n",
    "\n",
    "# create an environment for pytorch geometric\n",
    "module load gcc\n",
    "conda create -n pytorch_geometric pytorch cudatoolkit=10.2\n",
    "conda activate pytorch_geometric\n",
    "\n",
    "pip install torch-scatter\n",
    "pip install torch-sparse\n",
    "pip install torch-geometric\n",
    "pip install torch-cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731aab36-d5bb-4c5d-bece-ec21783dd7fa",
   "metadata": {},
   "source": [
    "## JADE-2\n",
    "\n",
    "### Miniconda installer\n",
    "\n",
    "```bash\n",
    "...\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "...\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ea8d1-52a9-4085-9008-10d1dd60ed15",
   "metadata": {},
   "source": [
    "## Jupyter Notebook to HPC\n",
    "\n",
    "It's preferable to use a static job on the HPC. To do this, you could test out different ideas locally in a Jupyter Notebook, then when ready convert this to an executable script (`.py`) and move it over. \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff16b1-ed60-47ee-a16d-19acfdda17dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e33cfd64-4afb-4e03-8712-3d9935879e91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [Ray Train](https://docs.ray.io/en/latest/train/train.html)\n",
    "\n",
    "These examples use Ray Train in a static job on a HPC.\n",
    "Ray handles most of the complexity of distributing the work, with minimal changes to your [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) or [PyTorch](https://pytorch.org/tutorials/beginner/dist_overview.html) code.\n",
    "\n",
    "- Python script examples:\n",
    "  - TensorFlow\n",
    "    - MNIST: [`tensorflow_ray_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/tensorflow_ray_mnist_example.py).  \n",
    "  - PyTorch\n",
    "    - Fashion MNIST: [`pytorch_ray_train_fashion_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/pytorch_ray_train_fashion_mnist_example.py).  \n",
    "- Then submit the job to HPC (choose one and update the Python script within it):\n",
    "  - [ARC4](https://arcdocs.leeds.ac.uk/systems/arc4.html) (SGE)  \n",
    "    - CPU: [`distributed_ml_on_arc4_cpu.bash`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_cpu.bash).  \n",
    "    - GPU: [`distributed_ml_on_arc4_gpu.bash`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_gpu.bash).  \n",
    "  - [Bede](https://bede-documentation.readthedocs.io/en/latest/) (SLURM)\n",
    "    - GPU: [`distributed_ml_on_bede.bash`](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_bede.bash).  \n",
    "  - [JADE-2](http://docs.jade.ac.uk/en/latest/index.html) (SLURM)\n",
    "    - GPU: ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fbf5b-68db-4b0f-b274-2c02cf2921a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ba867-497b-49da-9365-8ec52064aff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b6c73-a7ea-4e53-a2cf-0d1294aa5daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd26db-3e9d-4ada-8b60-ec674b674b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <distributed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Batch the dataset with the global batch size e.g., for 8 devices each capable of a btach of 64 use the global batch size of 512 (= 8 * 64).  \n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Horovod](https://horovod.ai/)\n",
    "- [DeepSpeed](https://www.deepspeed.ai/)\n",
    " \n",
    "### Resources\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebad9cd-bc43-4281-8729-06e7650fefee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
