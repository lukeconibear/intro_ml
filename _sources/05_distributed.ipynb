{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/04_distributed.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c725f-0aed-4b26-b2c0-6e02de0ad324",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3cc2fa-771a-4a39-a59a-1287d4973930",
   "metadata": {},
   "source": [
    "Examples of how to distribute deep learning on a High Performance Computer (HPC).\n",
    "\n",
    "## Contents\n",
    "\n",
    "These examples use [Ray Train](https://docs.ray.io/en/latest/train/train.html) in a static job on a HPC. Ray handles most of the complexity of distributing the work, with minimal changes to your [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) or [PyTorch](https://pytorch.org/tutorials/beginner/dist_overview.html) code.\n",
    "\n",
    "First, install the Python environments for the required HPC: [`install_python_environments.md`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/install_python_environments.md).  \n",
    "\n",
    "- Python script examples:\n",
    "  - TensorFlow\n",
    "    - MNIST end-to-end: [`tensorflow_mnist_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/tensorflow_mnist_example.py).  \n",
    "    - MNIST tuning: [`tensorflow_tune_mnist_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/tensorflow_tune_mnist_example.py).  \n",
    "    - Train linear model with Ray Datasets: [`tensorflow_linear_dataset_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/tensorflow_linear_dataset_example.py).  \n",
    "  - PyTorch\n",
    "    - Linear: [`pytorch_train_linear_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/pytorch_train_linear_example.py).  \n",
    "    - Fashion MNIST: [`pytorch_train_fashion_mnist_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/pytorch_train_fashion_mnist_example.py).  \n",
    "    - HuggingFace Transformer: [`pytorch_transformers_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/pytorch_transformers_example.py).  \n",
    "    - Tune linear model with Ray Datasets: [`pytorch_tune_linear_dataset_example.py`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/pytorch_tune_linear_dataset_example.py).  \n",
    "- Then submit the job to HPC (choose one and update the Python script within it):\n",
    "  - [ARC4](https://arcdocs.leeds.ac.uk/systems/arc4.html) (SGE)  \n",
    "    - CPU: [`ray_train_on_arc4_cpu.bash`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/ray_train_on_arc4_cpu.bash).  \n",
    "    - GPU: [`ray_train_on_arc4_gpu.bash`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/ray_train_on_arc4_gpu.bash).  \n",
    "  - [Bede](https://bede-documentation.readthedocs.io/en/latest/) (SLURM)\n",
    "    - GPU: [`ray_train_on_bede.bash`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/ray_train_on_bede.bash).  \n",
    "  - [JADE-2](http://docs.jade.ac.uk/en/latest/index.html) (SLURM)\n",
    "    - GPU: ...\n",
    "\n",
    "It's preferable to use a static job on the HPC. To do this, you could test out different ideas locally in a Jupyter Notebook, then when ready convert this to an executable script (`.py`) and move it over. However, it is also possible to use Jupyter Notebooks interactively on the HPC following the instructions here: [`jupyter_notebook_to_hpc.md`](https://github.com/lukeconibear/distributed_deep_learning/blob/main/jupyter_notebook_to_hpc.md).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678d72d-b008-43d9-8e8f-f6911661cf49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172846d1-c075-4cfd-81f4-7401dd0135e7",
   "metadata": {},
   "source": [
    "https://keras.io/guides/distributed_training/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4ca1f-42f4-4e7c-bb38-73c30401fc66",
   "metadata": {},
   "source": [
    "Synchronous data-parallel training on all available GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b487b5-a8d6-421a-831b-c2fab2f09d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_strategy = tf.distribute.MirrorStratergy()\n",
    "# with distribution_strategy.scope():\n",
    "#     # Everything that creates variables should be under the strategy scope.\n",
    "#     # In general this is only model construction and compile()\n",
    "#     model = build_model()\n",
    "#     model.compile(optimiser, loss)\n",
    "#     model.fit(dataset, epochs=epochs, callbacks=callbacks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d227b3f-2910-4d3b-82bb-8ab241cc1772",
   "metadata": {},
   "source": [
    "should the `model.fit` call be inside or outside the scope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b677227-469f-4b11-8ae9-9d8b6c562264",
   "metadata": {},
   "source": [
    "#$ -cwd\n",
    "\n",
    "not\n",
    "\n",
    "#$ -cwd -V\n",
    "\n",
    "so have to specific the reproducible environment with the job submission (not copied over from the terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e991d8-5171-4a24-908c-1aae5016bf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa82c005-5721-434c-a8c7-d5eb5f2f2afb",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "\n",
    "For longer or distributed training, it's helpful to save the model at regular intervals in case it crashes during training.\n",
    "\n",
    "This is model checkpointing, and is done via callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12857fb-0a33-4b7b-9ad1-318a158de9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 14:10:08.522624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-16 14:10:08.522642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f161fc-1a28-4b12-9fe8-fad13ff441bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='path/to/my/model_{epoch}',\n",
    "    save_freq='epoch'  # save a model version at the end of each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a97669-e61b-4615-b8f2-f9e9b7914c33",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b75abc-f03c-4323-a0cf-3c24c11a01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813e565-680a-48c9-94e7-b97a584bec20",
   "metadata": {},
   "source": [
    "View them with:\n",
    "\n",
    "`tensorboard --logdir=./logs`\n",
    "\n",
    "Also, in-line in [Jupyter Notebooks / Google Colab](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754aab4-d77f-49ba-99e3-459db572bb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3974fe93-af71-489f-926d-67d542b2f869",
   "metadata": {},
   "source": [
    "## Example: Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1a84b-3d74-4bab-8d2d-5eaa08fadb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    callback_model_checkpoint,\n",
    "    callback_tensorboard,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027f592-a249-41cf-bff5-6e842e358f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(dataset, epochs=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfa02a-60cf-4e35-946c-d6d90dd6c44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafbd9b-1ac6-4017-9e13-63b734862265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd26db-3e9d-4ada-8b60-ec674b674b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <distributed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Horovod](https://horovod.ai/)\n",
    "- [DeepSpeed](https://www.deepspeed.ai/)\n",
    " \n",
    "### Resources\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88b4fd-f076-480a-8ce8-703a115cd920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
