{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/05_distributed.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8aa72b-89d2-47e8-9dae-d6eff282617a",
   "metadata": {},
   "source": [
    "Distributing training over multiple devices generally uses either:\n",
    "\n",
    "- [Data parallelism](https://developers.google.com/machine-learning/glossary/#data-parallelism)\n",
    "    - Single model copied to multiple devices.\n",
    "    - Split data over multiple devices.\n",
    "    - Useful for big data.\n",
    "- [Model parallelism](https://developers.google.com/machine-learning/glossary/#model-parallelism)\n",
    "    - Split model over multiple devices.\n",
    "    - Single data copied to multiple devices.\n",
    "    - Useful for big models.\n",
    "    \n",
    "This lesson focuses on data parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f972d1-8eac-424a-b800-19a6c1f6ef04",
   "metadata": {},
   "source": [
    "## [Ray Train](https://docs.ray.io/en/latest/train/train.html)\n",
    "\n",
    "Ray Train simplifies distributed deep learning for TensorFlow and PyTorch.\n",
    "\n",
    "It handles the set up for you (e.g., [`TF_CONFIG`](https://www.tensorflow.org/guide/distributed_training#setting_up_the_tf_config_environment_variable) in TensorFlow).\n",
    "\n",
    "There are a range of examples [here](https://docs.ray.io/en/latest/train/examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192221c-7f41-4b0d-abc5-2d2045db01e5",
   "metadata": {},
   "source": [
    "### [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864cbb8-4483-4baa-99ea-ae49a58fa6db",
   "metadata": {},
   "source": [
    "Here is an [MNIST example](https://docs.ray.io/en/latest/train/examples/tensorflow_mnist_example.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0401135c-c7be-4ef6-83ce-4476dc9dd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import ray.train as train\n",
    "import tensorflow as tf\n",
    "from ray.train import Trainer\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dd1ed-38e0-455c-9f2b-08445bf302a4",
   "metadata": {},
   "source": [
    "#### [Define callback for reporting](https://docs.ray.io/en/latest/train/user_guide.html#logging-monitoring-and-callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe996158-18c1-4d96-8d6a-f57fd9a46110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainReportCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train.report(**logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e6947-55dd-4e48-a550-4213b4e16bc9",
   "metadata": {},
   "source": [
    "#### Set up the dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef5e61-5392-4edd-bdaf-fec50b2752cf",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "The default [auto-sharding](https://www.tensorflow.org/api_docs/python/tf/data/experimental/AutoShardPolicy) by `FILE` can cause warning messages. Instead auto-shard by data: `tf.data.experimental.AutoShardPolicy.DATA`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68b1ba8c-03a4-434e-9409-8ff0e17246e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size):\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    \n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = (\n",
    "        tf.data.experimental.AutoShardPolicy.DATA\n",
    "    )\n",
    "    train_dataset = train_dataset.with_options(options)\n",
    "    \n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5cc516c-9738-4397-97ae-309a568564e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_cnn_model(config):\n",
    "    learning_rate = config.get(\"lr\", 0.001)\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61991c2f-cf4b-4ef2-943d-bf22e3d40ba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Set up the training function for a _single_ worker\n",
    "\n",
    "You can [configure training](https://docs.ray.io/en/latest/train/user_guide.html#configuring-training) using the `config` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d2d3ca5a-badd-49b6-8cff-5b8c29c62c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    batch_size = 64\n",
    "    single_worker_dataset = mnist_dataset(batch_size)\n",
    "    single_worker_model = build_and_compile_cnn_model(config)\n",
    "    single_worker_model.fit(\n",
    "        single_worker_dataset, epochs=config[\"epochs\"], steps_per_epoch=70\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "405f7875-5432-4ac1-ab40-240b72d95310",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"epochs\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e6eb09cc-1b1a-4884-9d4f-026c0115816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2.2926 - accuracy: 0.1507\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2.2321 - accuracy: 0.2761\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2.1645 - accuracy: 0.3920\n"
     ]
    }
   ],
   "source": [
    "train_func(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea930e9-6620-4e67-903a-52c3f76da168",
   "metadata": {},
   "source": [
    "#### [Update training function](https://docs.ray.io/en/latest/train/user_guide.html#update-training-function)\n",
    "\n",
    "1. Set the _global_ batch size\n",
    "    - Each worker will process the same size batch as in the single-worker code.\n",
    "2. Choose your TensorFlow distributed training strategy.\n",
    "    - In this example we use the [MultiWorkerMirroredStrategy](https://www.tensorflow.org/guide/distributed_training#multiworkermirroredstrategy) for synchronous training of multiple workers across many machines.\n",
    "    - Within the strategy scope, you build a compiled the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8604122-4b78-4459-a49e-0716854003fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "    num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_and_compile_cnn_model(config)\n",
    "\n",
    "    history = multi_worker_model.fit(\n",
    "        multi_worker_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[TrainReportCallback()],\n",
    "        verbose=False,\n",
    "    )\n",
    "    results = history.history\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fab04c-ae80-415d-9f41-de20b03b65ae",
   "metadata": {},
   "source": [
    "#### [Create Ray Train Trainer](https://docs.ray.io/en/latest/train/user_guide.html#create-ray-train-trainer)\n",
    "\n",
    "The `Trainer` manages state and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c919384c-3a06-4cc5-a733-e98257473ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tensorflow_mnist(num_workers=1, use_gpu=False, epochs=4):\n",
    "    trainer = Trainer(backend=\"tensorflow\", num_workers=num_workers, use_gpu=use_gpu)\n",
    "    trainer.start()\n",
    "    results = trainer.run(\n",
    "        train_func=train_func, config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": epochs}\n",
    "    )\n",
    "    trainer.shutdown()\n",
    "    print(f\"Results: {results[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6ad38-736d-40d1-9025-655f838509a5",
   "metadata": {},
   "source": [
    "#### [Run the training](https://docs.ray.io/en/latest/train/user_guide.html#run-training-function)\n",
    "\n",
    "Initialise and shutdown the Ray client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c478acf-9517-4cef-91a5-d26506e7b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47fce682-d5af-495b-b2da-bed0feefefff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:45:59,378\tINFO trainer.py:199 -- Trainer logs will be logged in: /home/earlacoa/ray_results/train_2022-03-25_15-45-59\n",
      "2022-03-25 15:45:59,858\tINFO trainer.py:205 -- Run results will be logged in: /home/earlacoa/ray_results/train_2022-03-25_15-45-59/run_001\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=615413)\u001b[0m 2022-03-25 15:45:59.976682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=615413)\u001b[0m 2022-03-25 15:45:59.976705: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:00.933622: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:00.933645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.783876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.783907: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.783919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (UOL-LAP-5G6CZH3): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.784292: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.794779: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.0.37:58421}\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:01.794904: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:437] Started server with target: grpc://192.168.0.37:58421\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=615414)\u001b[0m 2022-03-25 15:46:02.481199: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'loss': [2.2843410968780518, 2.234750747680664, 2.1810903549194336, 2.1127052307128906], 'accuracy': [0.16026785969734192, 0.3738839328289032, 0.5381696224212646, 0.6267856955528259]}\n"
     ]
    }
   ],
   "source": [
    "# cpu\n",
    "# train_tensorflow_mnist()\n",
    "\n",
    "# gpu\n",
    "# train_tensorflow_mnist(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3c511b19-86e0-4a82-8e6e-48f10f51d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31ed3a-e683-4990-ab93-ed849418a360",
   "metadata": {},
   "source": [
    "This Python script is in full [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/tensorflow_ray_train_mnist_example.py).\n",
    "\n",
    "The job submission script is (also [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_cpu.bash)):\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -l h_rt=00:30:00\n",
    "#$ -pe smp 12\n",
    "#$ -l h_vmem=6G\n",
    "\n",
    "conda activate intro_ml\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib  # (sometimes needed)\n",
    "\n",
    "python tensorflow_ray_train_mnist_example.py --num-workers 12 --epochs 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae10ba3-b47a-4974-beb7-d947eec175a0",
   "metadata": {},
   "source": [
    "In this simple example using 12 CPUs, the job efficiency (using `qacct -j <JOBID>`):\n",
    "\n",
    "```\n",
    "Efficiency = 100 * cpu / (ru_wallclock * slots)\n",
    "Efficiency = 100 * 10214 / (928 * 12)\n",
    "Efficiency = 92 %\n",
    "```\n",
    "\n",
    "92% is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7f591-53aa-4861-aea5-b14994d58d9c",
   "metadata": {},
   "source": [
    "To run on the GPU ([submission script](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_gpu.bash)):\n",
    "- Replace `#$ -pe smp 4` with `#$ -l coproc_v100=1`.\n",
    "- Add `--use-gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10195389-5b85-403a-9ae8-076c3589a536",
   "metadata": {},
   "source": [
    "### [PyTorch](https://pytorch.org/tutorials/beginner/dist_overview.html)\n",
    "\n",
    "Here is an [Fashion MNIST example](https://docs.ray.io/en/latest/train/examples/train_fashion_mnist_example.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f91ad439-f82c-4823-b862-6a8c9159f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train.trainer import Trainer\n",
    "from ray.train.callbacks import JsonLoggerCallback\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5b4fb-2f70-4456-b781-1a62c0b57836",
   "metadata": {},
   "source": [
    "#### Set up the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e6cf03ff-9e75-4823-9326-85710648a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb49c7f78be54398b7ea36e56b250af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/earlacoa/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e3e7edf80441aa9d631819e87ef6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/earlacoa/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae42f33fa3004c18ad14b3ca779da7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/earlacoa/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395e0dbcddfe492296c03a021716ea4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/earlacoa/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /home/earlacoa/data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"~/data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"~/data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "acc028ef-e5c2-4c3c-a2df-cc89e000cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 10), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae290f-20a3-4f3d-8f55-2e89cf4641a8",
   "metadata": {},
   "source": [
    "#### Define training and validation per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "99236486-7cd9-4c80-9afc-375522805ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) // train.world_size()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5c57e66-c084-4828-bc14-216f13c53e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // train.world_size()\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n \"\n",
    "          f\"Accuracy: {(100 * correct):>0.1f}%, \"\n",
    "          f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c35dfa-5c5c-40bc-9b51-07f34399bccf",
   "metadata": {},
   "source": [
    "#### [Setup distributed training function](https://docs.ray.io/en/latest/train/user_guide.html#update-training-function)\n",
    "\n",
    "Use `ray.train.torch.prepare_model` to automatically move your model to the right device.\n",
    "\n",
    "Use `ray.train.torch.prepare_data_loader` utility functions to setup your data for distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3f274752-831c-4c0b-a262-d44f83ef3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config: Dict):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    worker_batch_size = batch_size // train.world_size()\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=worker_batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=worker_batch_size)\n",
    "\n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    # Create model.\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    loss_results = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        train.report(loss=loss)\n",
    "        loss_results.append(loss)\n",
    "\n",
    "    return loss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745b483-e9a7-40b3-b840-7556ce919abb",
   "metadata": {},
   "source": [
    "#### [Create Ray Train Trainer](https://docs.ray.io/en/latest/train/user_guide.html#create-ray-train-trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "48d91f56-7066-44ff-b2b6-ed6cad71dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(num_workers=1, use_gpu=False):\n",
    "    trainer = Trainer(\n",
    "        backend=\"torch\", num_workers=num_workers, use_gpu=use_gpu)\n",
    "    trainer.start()\n",
    "    result = trainer.run(\n",
    "        train_func=train_func,\n",
    "        config={\n",
    "            \"lr\": 1e-3,\n",
    "            \"batch_size\": 64,\n",
    "            \"epochs\": 4\n",
    "        },\n",
    "        callbacks=[JsonLoggerCallback()])\n",
    "    trainer.shutdown()\n",
    "    print(f\"Loss results: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba0bf9-1f18-49d5-af3f-317960974cd0",
   "metadata": {},
   "source": [
    "#### [Run the training](https://docs.ray.io/en/latest/train/user_guide.html#run-training-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d114c39-5041-45d6-8fa5-d3c2f992ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.37',\n",
       " 'raylet_ip_address': '192.168.0.37',\n",
       " 'redis_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-25_16-29-28_552181_560894/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-25_16-29-28_552181_560894/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-03-25_16-29-28_552181_560894',\n",
       " 'metrics_export_port': 38196,\n",
       " 'gcs_address': '192.168.0.37:43117',\n",
       " 'address': '192.168.0.37:43117',\n",
       " 'node_id': '790fd81aeb0811f07d2183039d15d093c6a6ee3a272d75fa8a64143e'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "691b98b5-7808-41bc-90fa-26f0a4417cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 16:29:32,512\tINFO trainer.py:199 -- Trainer logs will be logged in: /home/earlacoa/ray_results/train_2022-03-25_16-29-32\n",
      "2022-03-25 16:29:33,611\tINFO trainer.py:205 -- Run results will be logged in: /home/earlacoa/ray_results/train_2022-03-25_16-29-32/run_001\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m 2022-03-25 16:29:33,566\tINFO torch.py:66 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m 2022-03-25 16:29:34,045\tINFO torch.py:244 -- Moving model to device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.306230  [    0/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.301374  [ 6400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.288759  [12800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.285810  [19200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.291880  [25600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.275090  [32000/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.289195  [38400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.276231  [44800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.260754  [51200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.255165  [57600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m  Accuracy: 25.4%, Avg loss: 2.259322 \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.260004  [    0/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.267538  [ 6400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.232293  [12800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.237170  [19200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.264318  [25600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.223731  [32000/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.261246  [38400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.235488  [44800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.200583  [51200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.197270  [57600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m  Accuracy: 27.4%, Avg loss: 2.203949 \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.203535  [    0/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.221236  [ 6400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.151671  [12800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.166765  [19200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.208966  [25600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.141864  [32000/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.203979  [38400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.154109  [44800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.101506  [51200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.098535  [57600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m  Accuracy: 39.5%, Avg loss: 2.101898 \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.105610  [    0/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.125648  [ 6400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.000034  [12800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.048515  [19200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.082726  [25600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.001524  [32000/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.104974  [38400/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 2.028362  [44800/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 1.988936  [51200/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m loss: 1.975192  [57600/60000]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m  Accuracy: 36.6%, Avg loss: 1.977916 \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=618603)\u001b[0m \n",
      "Loss results: [[2.2593223562665807, 2.2039488926055326, 2.10189779548888, 1.9779162703046373]]\n"
     ]
    }
   ],
   "source": [
    "# cpu\n",
    "# train_fashion_mnist()\n",
    "\n",
    "# gpu\n",
    "# train_fashion_mnist(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581fc5f-492e-4eb1-bad0-1524a7b4d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93781c8-9a77-4f0a-9225-347418038ae9",
   "metadata": {},
   "source": [
    "This Python script is in full [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/pytorch_ray_train_fashion_mnist_example.py).\n",
    "\n",
    "The job submission script is the same as before ([here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_cpu.bash)), except you use the line:\n",
    "\n",
    "```bash\n",
    "python tensorflow_ray_train_mnist_example.py --num-workers 12 --epochs 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d6c0b-1f18-4bdb-90ca-5790ab835673",
   "metadata": {},
   "source": [
    "In this simple example using 12 CPUs, the job efficiency (using `qacct -j <JOBID>`):\n",
    "\n",
    "```\n",
    "Efficiency = 100 * cpu / (ru_wallclock * slots)\n",
    "Efficiency = 100 * X / (X * 12)\n",
    "Efficiency = X %\n",
    "```\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d64be-5cb5-46c2-ba42-efeea5eab9c3",
   "metadata": {},
   "source": [
    "To run on the GPU ([submission script](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_gpu.bash)):\n",
    "- Replace `#$ -pe smp 4` with `#$ -l coproc_v100=1`.\n",
    "- Add `--use-gpu=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b29d0-5709-48be-9901-16722e4fa7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e178d-9b5d-4096-b522-b6b7801ad75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d9ea8d1-52a9-4085-9008-10d1dd60ed15",
   "metadata": {},
   "source": [
    "## Jupyter Notebook to HPC\n",
    "\n",
    "It's preferable to use a static job on the HPC. To do this, you could test out different ideas locally in a Jupyter Notebook, then when ready convert this to an executable script (`.py`) and move it over. \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff16b1-ed60-47ee-a16d-19acfdda17dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <distributed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Ensure works on a single workers first, _before_ going distributed.\n",
    "- Really ensure that you need multiple GPUs.\n",
    "- Batch the dataset with the global batch size e.g., for 8 devices each capable of a btach of 64 use the global batch size of 512 (= 8 * 64).  \n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Horovod](https://horovod.ai/)\n",
    "- [DeepSpeed](https://www.deepspeed.ai/)\n",
    " \n",
    "### Resources\n",
    "\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
