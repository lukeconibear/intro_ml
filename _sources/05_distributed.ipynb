{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/05_distributed.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78754a-ddf7-4ccd-a1a2-18a055f97adc",
   "metadata": {},
   "source": [
    "```{note}\n",
    "If youâ€™re in COLAB or have a local CUDA GPU, you can follow along with the more computationally intensive training in this lesson.\n",
    "\n",
    "For those in COLAB, ensure the session is using a GPU by going to: Runtime > Change runtime type > Hardware accelerator = GPU.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8aa72b-89d2-47e8-9dae-d6eff282617a",
   "metadata": {},
   "source": [
    "Distributing training over multiple devices generally uses either:\n",
    "\n",
    "- [Data parallelism](https://developers.google.com/machine-learning/glossary/#data-parallelism)\n",
    "    - Single model copied to multiple devices.\n",
    "    - Split data over multiple devices.\n",
    "    - Useful for big data.\n",
    "- [Model parallelism](https://developers.google.com/machine-learning/glossary/#model-parallelism)\n",
    "    - Split model over multiple devices.\n",
    "    - Single data copied to multiple devices.\n",
    "    - Useful for big models (for some architectures).\n",
    "    \n",
    "This lesson focuses on data parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f972d1-8eac-424a-b800-19a6c1f6ef04",
   "metadata": {},
   "source": [
    "## [Ray Train](https://docs.ray.io/en/latest/train/train.html)\n",
    "\n",
    "Ray Train simplifies distributed deep learning for TensorFlow and PyTorch.\n",
    "\n",
    "It handles the set up for you (e.g., [`TF_CONFIG`](https://www.tensorflow.org/guide/distributed_training#setting_up_the_tf_config_environment_variable) in TensorFlow).\n",
    "\n",
    "There are a range of examples [here](https://docs.ray.io/en/latest/train/examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03524baa-bf2a-4817-a0df-08b03c2d2142",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Note, Ray doesn't currently work on POWER9 machines e.g., Bede. See, [GitHub issue](https://github.com/ray-project/ray/issues/7476).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192221c-7f41-4b0d-abc5-2d2045db01e5",
   "metadata": {},
   "source": [
    "### [TensorFlow (Keras)](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864cbb8-4483-4baa-99ea-ae49a58fa6db",
   "metadata": {},
   "source": [
    "Here is an [MNIST example](https://docs.ray.io/en/latest/train/examples/tensorflow_mnist_example.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401135c-c7be-4ef6-83ce-4476dc9dd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import tensorflow as tf\n",
    "from ray.train import Trainer\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dd1ed-38e0-455c-9f2b-08445bf302a4",
   "metadata": {},
   "source": [
    "#### [Define callback for reporting](https://docs.ray.io/en/latest/train/user_guide.html#logging-monitoring-and-callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe996158-18c1-4d96-8d6a-f57fd9a46110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainReportCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ray.train.report(**logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e6947-55dd-4e48-a550-4213b4e16bc9",
   "metadata": {},
   "source": [
    "#### Set up the dataset and model\n",
    "\n",
    "The dataset will be split (sharded) across the workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef5e61-5392-4edd-bdaf-fec50b2752cf",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "The default [auto-sharding](https://www.tensorflow.org/tutorials/distribute/input#sharding) by `FILE` can cause warning messages if the data is in one file. Instead, auto-shard by data using: `tf.data.experimental.AutoShardPolicy.DATA`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1ba8c-03a4-434e-9409-8ff0e17246e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size):\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    ds_train = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = (\n",
    "        tf.data.experimental.AutoShardPolicy.DATA\n",
    "    )\n",
    "    ds_train = ds_train.with_options(options)\n",
    "\n",
    "    return ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc516c-9738-4397-97ae-309a568564e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_cnn_model(config):\n",
    "    learning_rate = config.get(\"lr\", 0.001)\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61991c2f-cf4b-4ef2-943d-bf22e3d40ba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Set up the training function for a _single_ worker\n",
    "\n",
    "You can [configure training](https://docs.ray.io/en/latest/train/user_guide.html#configuring-training) using the `config` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3ca5a-badd-49b6-8cff-5b8c29c62c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    batch_size = 64\n",
    "    single_worker_dataset = mnist_dataset(batch_size)\n",
    "    single_worker_model = build_and_compile_cnn_model(config)\n",
    "    single_worker_model.fit(\n",
    "        single_worker_dataset,\n",
    "        epochs=config[\"epochs\"],\n",
    "        steps_per_epoch=70,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f7875-5432-4ac1-ab40-240b72d95310",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"epochs\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb09cc-1b1a-4884-9d4f-026c0115816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_func(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea930e9-6620-4e67-903a-52c3f76da168",
   "metadata": {},
   "source": [
    "#### [Update training function](https://docs.ray.io/en/latest/train/user_guide.html#update-training-function)\n",
    "\n",
    "1. Set the _global_ batch size\n",
    "    - Each worker will process the same size batch as in the single-worker code.\n",
    "2. Choose your TensorFlow distributed training strategy.\n",
    "    - In this example we use the [MultiWorkerMirroredStrategy](https://www.tensorflow.org/guide/distributed_training#multiworkermirroredstrategy) for synchronous training of multiple workers across many machines.\n",
    "        - For multiple workers on _one_ machine, use [MirroredStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy).\n",
    "        - In general, the mirrored strategy mirrors the parameters across the workers, ensuring replicas are identical.\n",
    "    - Within the strategy scope context manager, you build and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8604122-4b78-4459-a49e-0716854003fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "    num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_and_compile_cnn_model(config)\n",
    "\n",
    "    history = multi_worker_model.fit(\n",
    "        multi_worker_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[TrainReportCallback()],\n",
    "        verbose=False,\n",
    "    )\n",
    "    results = history.history\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fab04c-ae80-415d-9f41-de20b03b65ae",
   "metadata": {},
   "source": [
    "#### [Create Ray Train Trainer](https://docs.ray.io/en/latest/train/user_guide.html#create-ray-train-trainer)\n",
    "\n",
    "The `Trainer` manages state and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919384c-3a06-4cc5-a733-e98257473ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tensorflow_mnist(num_workers=1, use_gpu=False, epochs=4):\n",
    "    trainer = Trainer(backend=\"tensorflow\", num_workers=num_workers, use_gpu=use_gpu)\n",
    "    trainer.start()\n",
    "    results = trainer.run(\n",
    "        train_func=train_func, config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": epochs}\n",
    "    )\n",
    "    trainer.shutdown()\n",
    "    print(f\"Results: {results[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6ad38-736d-40d1-9025-655f838509a5",
   "metadata": {},
   "source": [
    "#### [Run the training](https://docs.ray.io/en/latest/train/user_guide.html#run-training-function)\n",
    "\n",
    "Initialise and shutdown the Ray client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c478acf-9517-4cef-91a5-d26506e7b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fce682-d5af-495b-b2da-bed0feefefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "# train_tensorflow_mnist()\n",
    "\n",
    "# gpu\n",
    "# train_tensorflow_mnist(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c511b19-86e0-4a82-8e6e-48f10f51d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31ed3a-e683-4990-ab93-ed849418a360",
   "metadata": {},
   "source": [
    "This Python script is in full [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/tensorflow_ray_train_mnist_example.py).\n",
    "\n",
    "The job submission script is (also [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_cpu.bash)):\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -l h_rt=00:30:00\n",
    "#$ -pe smp 12\n",
    "#$ -l h_vmem=6G\n",
    "\n",
    "conda activate intro_ml\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib  # (sometimes needed)\n",
    "\n",
    "python tensorflow_ray_train_mnist_example.py --num-workers 12 --epochs 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae10ba3-b47a-4974-beb7-d947eec175a0",
   "metadata": {},
   "source": [
    "In this simple example using 12 CPUs, the job efficiency (using `qacct -j <JOBID>`):\n",
    "\n",
    "```\n",
    "Efficiency = 100 * cpu / (ru_wallclock * slots)\n",
    "Efficiency = 100 * 10214 / (928 * 12)\n",
    "Efficiency = 92 %\n",
    "```\n",
    "\n",
    "92% is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7f591-53aa-4861-aea5-b14994d58d9c",
   "metadata": {},
   "source": [
    "To run on the GPU ([submission script](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_gpu.bash)):\n",
    "- Replace `#$ -pe smp 4` with `#$ -l coproc_v100=1`.\n",
    "- Add `--use-gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10195389-5b85-403a-9ae8-076c3589a536",
   "metadata": {},
   "source": [
    "### [PyTorch](https://pytorch.org/tutorials/beginner/dist_overview.html)\n",
    "\n",
    "Can also distribute with [Ray Train](https://docs.ray.io/en/latest/train/examples/train_fashion_mnist_example.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f754603-33b7-44ef-a1db-ce925579564a",
   "metadata": {},
   "source": [
    "To share data on a single filesystem, download the dataset once:\n",
    "\n",
    "```python\n",
    "Trainer(prepare_data_per_node=False)\n",
    "```\n",
    "\n",
    "The default behaviour is to download the data _once per node_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f3d77-5de1-47fb-9846-1d3becf2acc6",
   "metadata": {},
   "source": [
    "#### [DDP Strategy](https://pytorch-lightning.readthedocs.io/en/stable/advanced/model_parallel.html#ddp-optimizations)\n",
    "\n",
    "\n",
    "```python\n",
    "# train on 8 GPUs, using the DDP strategy\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=8, strategy=\"ddp\")\n",
    "```\n",
    "...\n",
    "\n",
    "\n",
    "```python\n",
    "# train on multiple GPUs across nodes (uses 8 GPUs in total)\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=2, num_nodes=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8fc19-bf0b-4a38-9691-196d166a303b",
   "metadata": {},
   "source": [
    "`num_workers`\n",
    "\n",
    "https://pytorch-lightning.readthedocs.io/en/stable/guides/speed.html#num-workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa4f0b-0a72-4b94-9d33-090cd551565b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a2155-16fe-4581-b866-8fb59329c722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ad439-f82c-4823-b862-6a8c9159f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n",
    "import torch\n",
    "from ray.train.callbacks import JsonLoggerCallback\n",
    "from ray.train.trainer import Trainer\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5b4fb-2f70-4456-b781-1a62c0b57836",
   "metadata": {},
   "source": [
    "#### Set up the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf03ff-9e75-4823-9326-85710648a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = datasets.FashionMNIST(\n",
    "#     root=\"~/data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )\n",
    "\n",
    "# test_data = datasets.FashionMNIST(\n",
    "#     root=\"~/data\",\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc028ef-e5c2-4c3c-a2df-cc89e000cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae290f-20a3-4f3d-8f55-2e89cf4641a8",
   "metadata": {},
   "source": [
    "#### Define training and validation per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99236486-7cd9-4c80-9afc-375522805ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) // ray.train.world_size()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c57e66-c084-4828-bc14-216f13c53e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // ray.train.world_size()\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n \"\n",
    "        f\"Accuracy: {(100 * correct):>0.1f}%, \"\n",
    "        f\"Avg loss: {test_loss:>8f} \\n\"\n",
    "    )\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c35dfa-5c5c-40bc-9b51-07f34399bccf",
   "metadata": {},
   "source": [
    "#### [Setup distributed training function](https://docs.ray.io/en/latest/train/user_guide.html#update-training-function)\n",
    "\n",
    "Use `ray.train.torch.prepare_model` to automatically move your model to the right device.\n",
    "\n",
    "Use `ray.train.torch.prepare_data_loader` utility functions to setup your data for distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f274752-831c-4c0b-a262-d44f83ef3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config: Dict):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    worker_batch_size = batch_size // ray.train.world_size()\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=worker_batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=worker_batch_size)\n",
    "\n",
    "    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = ray.train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    # Create model.\n",
    "    model = NeuralNetwork()\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    loss_results = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        ray.train.report(loss=loss)\n",
    "        loss_results.append(loss)\n",
    "\n",
    "    return loss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745b483-e9a7-40b3-b840-7556ce919abb",
   "metadata": {},
   "source": [
    "#### [Create Ray Train Trainer](https://docs.ray.io/en/latest/train/user_guide.html#create-ray-train-trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d91f56-7066-44ff-b2b6-ed6cad71dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(num_workers=1, use_gpu=False):\n",
    "    trainer = Trainer(backend=\"torch\", num_workers=num_workers, use_gpu=use_gpu)\n",
    "    trainer.start()\n",
    "    result = trainer.run(\n",
    "        train_func=train_func,\n",
    "        config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4},\n",
    "        callbacks=[JsonLoggerCallback()],\n",
    "    )\n",
    "    trainer.shutdown()\n",
    "    print(f\"Loss results: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba0bf9-1f18-49d5-af3f-317960974cd0",
   "metadata": {},
   "source": [
    "#### [Run the training](https://docs.ray.io/en/latest/train/user_guide.html#run-training-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d114c39-5041-45d6-8fa5-d3c2f992ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b98b5-7808-41bc-90fa-26f0a4417cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu\n",
    "# train_fashion_mnist()\n",
    "\n",
    "# gpu\n",
    "# train_fashion_mnist(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581fc5f-492e-4eb1-bad0-1524a7b4d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93781c8-9a77-4f0a-9225-347418038ae9",
   "metadata": {},
   "source": [
    "This Python script is in full [here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/pytorch_ray_train_fashion_mnist_example.py).\n",
    "\n",
    "The job submission script is the same as before ([here](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_cpu.bash)), except you use the line:\n",
    "\n",
    "```bash\n",
    "python tensorflow_ray_train_mnist_example.py --num-workers 12 --epochs 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d6c0b-1f18-4bdb-90ca-5790ab835673",
   "metadata": {},
   "source": [
    "In this simple example using 12 CPUs, the job efficiency (using `qacct -j <JOBID>`):\n",
    "\n",
    "```\n",
    "Efficiency = 100 * cpu / (ru_wallclock * slots)\n",
    "Efficiency = 100 * X / (X * 12)\n",
    "Efficiency = X %\n",
    "```\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d64be-5cb5-46c2-ba42-efeea5eab9c3",
   "metadata": {},
   "source": [
    "To run on the GPU ([submission script](https://github.com/lukeconibear/intro_ml/blob/main/docs/distributed/distributed_ml_on_arc4_gpu.bash)):\n",
    "- Replace `#$ -pe smp 4` with `#$ -l coproc_v100=1`.\n",
    "- Add `--use-gpu=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf4c2d-1031-47df-a076-863634cf360d",
   "metadata": {},
   "source": [
    "## [PyTorch (Lightning)](https://pytorch-lightning.readthedocs.io/en/stable/clouds/cluster.html)\n",
    "\n",
    "\n",
    "[SLURM](https://pytorch-lightning.readthedocs.io/en/stable/clouds/cluster.html#slurm-managed-cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0054c74-183c-48d4-8beb-c920aef262e3",
   "metadata": {},
   "source": [
    "```python\n",
    "# train.py\n",
    "def main(hparams):\n",
    "    model = LightningTemplateModel(hparams)\n",
    "\n",
    "    trainer = Trainer(accelerator=\"gpu\", devices=8, num_nodes=4, strategy=\"ddp\")\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    parent_parser = ArgumentParser(add_help=False)\n",
    "    hyperparams = parser.parse_args()\n",
    "\n",
    "    # TRAIN\n",
    "    main(hyperparams)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91254bc-9913-4fb7-8a30-bcf77e85d638",
   "metadata": {},
   "source": [
    "```bash\n",
    "# (submit.sh)\n",
    "#!/bin/bash -l\n",
    "\n",
    "# SLURM SUBMIT SCRIPT\n",
    "#SBATCH --nodes=4\n",
    "#SBATCH --gres=gpu:8\n",
    "#SBATCH --ntasks-per-node=8\n",
    "#SBATCH --mem=0\n",
    "#SBATCH --time=0-02:00:00\n",
    "\n",
    "conda activate swd8_intro_ml\n",
    "\n",
    "srun python3 train.py\n",
    "```\n",
    "\n",
    "```\n",
    "sbatch submit.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2eb480-f4ba-44a4-88a0-dee5b9993ccb",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Some errors can show up as an [NCCL](https://developer.nvidia.com/nccl) issue.  \n",
    "\n",
    "Set the `NCCL_DEBUG=INFO` environment variable to see the ACTUAL error:  \n",
    "\n",
    "`NCCL_DEBUG=INFO python train.py`  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044acf3f-b994-4fea-b45a-ed3af02013cc",
   "metadata": {},
   "source": [
    "## Jupyter Notebook to HPC\n",
    "\n",
    "Once you've finished testing out different ideas locally in a Jupyter Notebook, you can then convert this to an exercutable script to run on a HPC.\n",
    "\n",
    "This is because the HPCs (currently accessible at Leeds, at least) are suitable for non-interactive batch jobs.\n",
    "\n",
    "The steps are to:\n",
    "\n",
    "- [Clean non-essential code](clean_nonessential_code)\n",
    "- [Refactor Jupyter Notebook code into functions](refactor_into_functions)\n",
    "- [Create a Python script](create_python_script)\n",
    "- [Create submission script](create_submission_script)\n",
    "- [(Optional) Create unit tests](create_unit_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c2064-5b2a-4e68-88fe-dad5c41e6c3d",
   "metadata": {},
   "source": [
    "(clean_nonessential_code)=\n",
    "### Clean non-essential code\n",
    "\n",
    "Some code added during the experimentation phase was only needed to test out ideas and explore the data.\n",
    "\n",
    "This non-essential code can be removed to make it more maintainable and performant.\n",
    "\n",
    "Let's use the example from the [TensorFlow Datasets MNIST example](tensorflow_datasets) we saw in Lesson 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db364bea-8762-4079-b9df-00ca02ae2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "<_OptionsDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='/home/earlacoa/tensorflow_datasets/mnist/3.0.1',\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n",
      "Model: \"functional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 128)               16512     \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# global setup\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# download the data\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "print(ds_train)\n",
    "print(ds_info)\n",
    "\n",
    "# preprocess the data\n",
    "def normalise_image(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "# create data pipelines\n",
    "def training_pipeline(ds_train):\n",
    "    ds_train = ds_train.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "    return ds_train\n",
    "\n",
    "\n",
    "def test_pipeline(ds_test):\n",
    "    ds_test = ds_test.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "    return ds_test\n",
    "\n",
    "\n",
    "ds_train = training_pipeline(ds_train)\n",
    "ds_val = training_pipeline(ds_val)\n",
    "ds_test = test_pipeline(ds_test)\n",
    "\n",
    "\n",
    "# create the model\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"functional\")\n",
    "\n",
    "# view the model\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# plot the model accuracy\n",
    "epochs_range = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "plt.plot(epochs_range, history.history[\"accuracy\"], \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(\n",
    "    epochs_range, history.history[\"val_accuracy\"], \"b\", label=\"Validation accuracy\"\n",
    ")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0.9, 1.0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# save the model\n",
    "path_models = f\"{os.getcwd()}/models\"\n",
    "model.save(f\"{path_models}/model_tf_mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99047dde-1025-424c-b918-a388f5d9d09f",
   "metadata": {},
   "source": [
    "Now, removing non-essential code, now the experimentation phase is complete.\n",
    "\n",
    "Here this included:\n",
    "\n",
    "- Removing downloading data information.\n",
    "- Removing unrequired print statements.\n",
    "- Viewing model summary.\n",
    "- Removing/replacing plots with text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "261a8b56-6eca-43a1-92d5-407a6d617099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Training accuracy: [0.88, 0.95, 0.96, 0.97, 0.97]\n",
      "Validation accuracy: [0.94, 0.96, 0.97, 0.97, 0.97]\n",
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# global setup\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# download the data\n",
    "(ds_train, ds_val, ds_test) = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n",
    "\n",
    "# preprocess the data\n",
    "def normalise_image(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "# create data pipelines\n",
    "def training_pipeline(ds_train):\n",
    "    ds_train = ds_train.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "    return ds_train\n",
    "\n",
    "\n",
    "def test_pipeline(ds_test):\n",
    "    ds_test = ds_test.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "    return ds_test\n",
    "\n",
    "\n",
    "ds_train = training_pipeline(ds_train)\n",
    "ds_val = training_pipeline(ds_val)\n",
    "ds_test = test_pipeline(ds_test)\n",
    "\n",
    "\n",
    "# create the model\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"functional\")\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# view the model accuracy\n",
    "print(f\"Training accuracy: {[round(num, 2) for num in history.history['accuracy']]}\")\n",
    "print(\n",
    "    f\"Validation accuracy: {[round(num, 2) for num in history.history['val_accuracy']]}\"\n",
    ")\n",
    "\n",
    "# save the model\n",
    "path_models = f\"{os.getcwd()}/models\"\n",
    "model.save(f\"{path_models}/model_tf_mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c735a7-9c23-4614-8fe1-23c007f63aaf",
   "metadata": {},
   "source": [
    "(refactor_into_functions)=\n",
    "### Refactor Jupyter Notebook code into functions\n",
    "\n",
    "Now, any code that is not already in functions, can be refactored into functions.\n",
    "\n",
    "Modularising the code like this helps with diagnosing errors and creating tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c5f1100-48d6-4d73-aa3f-805d15293c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/earlacoa/repos/swd8_intro_ml/docs/models/model_tf_mnist/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: [0.88, 0.95, 0.96, 0.97, 0.97]\n",
      "Validation accuracy: [0.94, 0.96, 0.97, 0.97, 0.97]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# global setup\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# download the data\n",
    "def download_data():\n",
    "    (ds_train, ds_val, ds_test) = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=False,\n",
    "    )\n",
    "    return ds_train, ds_val, ds_test\n",
    "\n",
    "\n",
    "# preprocess the data\n",
    "def normalise_image(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "# create data pipelines\n",
    "def training_pipeline(ds_train):\n",
    "    ds_train = ds_train.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "    return ds_train\n",
    "\n",
    "\n",
    "def test_pipeline(ds_test):\n",
    "    ds_test = ds_test.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "    return ds_test\n",
    "\n",
    "\n",
    "# create and compile the model\n",
    "def create_and_compile_model():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "    x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"functional\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "def train_model():\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "# save the model\n",
    "def save_model(model):\n",
    "    path_models = f\"{os.getcwd()}/models\"\n",
    "    model.save(f\"{path_models}/model_tf_mnist\")\n",
    "\n",
    "\n",
    "# combine the functions in a call to main\n",
    "def main():\n",
    "    ds_train, ds_val, ds_test = download_data()\n",
    "\n",
    "    ds_train = training_pipeline(ds_train)\n",
    "    ds_val = training_pipeline(ds_val)\n",
    "    ds_test = test_pipeline(ds_test)\n",
    "\n",
    "    model = create_and_compile_model()\n",
    "    history = train_model()\n",
    "    save_model(model)\n",
    "\n",
    "\n",
    "# run the functions\n",
    "main()\n",
    "\n",
    "# view the model accuracy\n",
    "print(f\"Training accuracy: {[round(num, 2) for num in history.history['accuracy']]}\")\n",
    "print(\n",
    "    f\"Validation accuracy: {[round(num, 2) for num in history.history['val_accuracy']]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8197e4-a426-4629-8f3b-b67acb1cff6a",
   "metadata": {},
   "source": [
    "(create_python_script)=\n",
    "### Create a Python script\n",
    "\n",
    "First, the call to `main()` should be placed inside a conditional invocation i.e.,:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "Now, the script can be called from a terminal by running `python script.py`.\n",
    "\n",
    "Then, the rest of the code can be convert by either:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8e7db-e3c8-4411-930c-79d08bc5db2e",
   "metadata": {},
   "source": [
    "#### Option 1 (recommended)\n",
    "\n",
    "Convert a _single cell_ to a script using the `%%writefile` IPython magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12f0195d-937e-4847-bc35-a001a8718c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing jupyter-to-hpc_tf-mnist-example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jupyter-to-hpc_tf-mnist-example.py\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# global setup\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# download the data\n",
    "def download_data():\n",
    "    (ds_train, ds_val, ds_test) = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=False,\n",
    "    )\n",
    "    return ds_train, ds_val, ds_test\n",
    "\n",
    "\n",
    "# preprocess the data\n",
    "def normalise_image(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "# create data pipelines\n",
    "def training_pipeline(ds_train):\n",
    "    ds_train = ds_train.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "    return ds_train\n",
    "\n",
    "\n",
    "def test_pipeline(ds_test):\n",
    "    ds_test = ds_test.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "    return ds_test\n",
    "\n",
    "\n",
    "# create and compile the model\n",
    "def create_and_compile_model():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "    x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"functional\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "def train_model():\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "# save the model\n",
    "def save_model(model):\n",
    "    path_models = f\"{os.getcwd()}/models\"\n",
    "    model.save(f\"{path_models}/model_tf_mnist\")\n",
    "\n",
    "\n",
    "# combine the functions in a call to main\n",
    "def main():\n",
    "    ds_train, ds_val, ds_test = download_data()\n",
    "\n",
    "    ds_train = training_pipeline(ds_train)\n",
    "    ds_val = training_pipeline(ds_val)\n",
    "    ds_test = test_pipeline(ds_test)\n",
    "\n",
    "    model = create_and_compile_model()\n",
    "    history = train_model()\n",
    "    save_model(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run the functions\n",
    "    main()\n",
    "\n",
    "    # view the model accuracy\n",
    "    print(\n",
    "        f\"Training accuracy: {[round(num, 2) for num in history.history['accuracy']]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation accuracy: {[round(num, 2) for num in history.history['val_accuracy']]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b5ebd-e3d2-4d72-87e5-f4cf2c9441e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Option 2\n",
    "\n",
    "Convert the _entire_ notebook to a script using the `nbconvert` package:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert \"my_notebook.ipynb\" --to script\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac845d9-4447-460f-b908-374b3391004f",
   "metadata": {},
   "source": [
    "#### Option 3\n",
    "\n",
    "Convert the _entire_ notebook to a script using the Jupyter menu.\n",
    "\n",
    "From within the Jupyter Notebook, click `File` > `Save and Export Notebook As ...` > `Executable Script`.\n",
    "\n",
    "This should convert the Jupyter Notebook to a `.py` file, and download it locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e145615-080f-4d65-b25d-3b8b3daf00e4",
   "metadata": {},
   "source": [
    "(create_submission_script)=\n",
    "### Create submission script\n",
    "\n",
    "For your HPC (e.g., ARC4), create the submission script.\n",
    "\n",
    "For example:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -l h_rt=00:05:00\n",
    "#$ -l coproc_v100=1\n",
    "\n",
    "conda activate swd8_intro_ml \n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib  # (sometimes required)\n",
    "\n",
    "python jupyter-to-hpc_tf-mnist-example.py\n",
    "```\n",
    "\n",
    "Ensure both of these files are on the HPC, alongside the corresponding conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ea8d1-52a9-4085-9008-10d1dd60ed15",
   "metadata": {
    "tags": []
   },
   "source": [
    "(create_unit_tests)=\n",
    "### (Optional) Create unit tests\n",
    "\n",
    "It's good practise to write [tests](https://the-turing-way.netlify.app/reproducible-research/testing.html) for your code.\n",
    "\n",
    "[pytest](https://docs.pytest.org/en/6.2.x/) are [NumPy](https://numpy.org/doc/stable/reference/testing.html) are both good, commonly-used tools for testing in Python.\n",
    "\n",
    "There are various [levels, types, and methods](https://softwaretestingfundamentals.com/) of testing.\n",
    "\n",
    "For example, you could [unit test](https://softwaretestingfundamentals.com/unit-testing/) individual functions, like the downloading and splitting of data:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def test_split_data(ds_train, ds_val, ds_test):\n",
    "    num_samples_train = len(ds_train)\n",
    "    num_samples_val = len(ds_val)\n",
    "    num_samples_test = len(ds_test)\n",
    "    \n",
    "    num_samples = num_samples_train + num_samples_val + num_samples_test\n",
    "    \n",
    "    np.testing.assert_almost_equal(num_samples_train / num_samples, 0.8, decimal=3)\n",
    "    np.testing.assert_almost_equal(num_samples_val / num_samples, 0.1, decimal=3)\n",
    "    np.testing.assert_almost_equal(num_samples_test / num_samples, 0.1, decimal=3)\n",
    "    \n",
    "\n",
    "test_split_data(ds_train, ds_val, ds_test)\n",
    "```\n",
    "\n",
    "You could also perform [system testing](https://softwaretestingfundamentals.com/system-testing/). For example, checking the final validation accuracy is above a threshold:\n",
    "\n",
    "```python\n",
    "def test_final_val_accuracy_above_threshold(threshold):\n",
    "    assert history.history['val_accuracy'][-1] >= threshold\n",
    "    \n",
    "test_final_val_accuracy_above_threshold(0.96)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <distributed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Ensure works on a single workers first, _before_ going distributed.\n",
    "- Ensure that you need the overhead of distributing over multiple GPUs e.g., could you instead use 1 GPU and model checkpointing?\n",
    "- Ensure that the problem is complex enough to use multiple GPUs efficiently.\n",
    "- Batch the dataset with the global batch size e.g., for 8 devices each capable of a btach of 64 use the global batch size of 512 (= 8 * 64).  \n",
    "- [Distributed training on PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/advanced/model_parallel.html)\n",
    "- Performance tips from [PyTorch](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Horovod](https://horovod.ai/)\n",
    "    - A library to make distributed deep learning fast and easy to use.\n",
    "- [DeepSpeed](https://www.deepspeed.ai/)\n",
    "    - A deep learning optimization library that makes distributed training easy, efficient, and effective.\n",
    "- [FairScale](https://fairscale.readthedocs.io/en/latest/)\n",
    "    - A PyTorch extension library for high performance and large scale training.\n",
    " \n",
    "### Resources\n",
    "\n",
    "- [PyTorch Distributed Overview](https://pytorch.org/tutorials/beginner/dist_overview.html)\n",
    "- [scikit-learn parallelism](https://scikit-learn.org/stable/computing/parallelism.html)\n",
    "- [Convert ML experiment to production](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-convert-ml-experiment-to-production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1927e-b738-4a75-9766-eb26f264aaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "swd8_intro_ml",
   "language": "python",
   "name": "swd8_intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
