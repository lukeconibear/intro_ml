{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/04_distributed.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8aa72b-89d2-47e8-9dae-d6eff282617a",
   "metadata": {},
   "source": [
    "Distributing training over multiple devices generally uses either:\n",
    "\n",
    "- Data parallelism\n",
    "    - Single model copied to multiple devices.\n",
    "    - Each device processes different batch of data.\n",
    "- Model parallelism\n",
    "    - Model split over multiple devices.\n",
    "    - Each device processes a single batch of data together.\n",
    "    \n",
    "This lesson focuses on data parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d8a2d-2e9a-4fb5-ac9e-1d5839a6d212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9192221c-7f41-4b0d-abc5-2d2045db01e5",
   "metadata": {},
   "source": [
    "## [TensorFlow](https://www.tensorflow.org/guide/distributed_training)\n",
    "\n",
    "You can use `tf.distribute.Strategy` to distribute models and training over multiple machines with minimal code changes.\n",
    "\n",
    "MirrorStrategy\n",
    "\n",
    "All-reduce\n",
    "\n",
    "Define a strategy.\n",
    "\n",
    "Within the strategy scope, compile and fit then model.\n",
    "\n",
    "global batch size\n",
    "\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model.compile(...)\n",
    "    model.fit(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379c067-7c5e-499c-9006-b52e03f075b8",
   "metadata": {},
   "source": [
    "### [Mirrored Strategy](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy)\n",
    "\n",
    "Supports distributed train\n",
    "\n",
    "[`TF_CONFIG`](https://www.tensorflow.org/guide/distributed_training#setting_up_the_tf_config_environment_variable)\n",
    "\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b01f2-34ab-4410-b402-3b614fd503f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b4a3ba-9430-480f-b0be-23a7f750f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 11:53:32.632593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-21 11:53:32.632608: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63233852-b12a-4ec2-a652-633cd4271b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    # Make a simple 2-layer densely-connected neural network.\n",
    "    inputs = tf.keras.Input(shape=(784,))\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b800ca-71c6-4c81-955a-95abbaaaa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    batch_size = 32\n",
    "    num_val_samples = 10000\n",
    "\n",
    "    # Return the MNIST dataset in the form of a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Preprocess the data (these are Numpy arrays)\n",
    "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    y_train = y_train.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    # Reserve num_val_samples samples for validation\n",
    "    x_val = x_train[-num_val_samples:]\n",
    "    y_val = y_train[-num_val_samples:]\n",
    "    x_train = x_train[:-num_val_samples]\n",
    "    y_train = y_train[:-num_val_samples]\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad22a6a0-5c67-4b25-8862-7284d4d5613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 11:53:56.173312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-21 11:53:56.173334: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-21 11:53:56.173346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (UOL-LAP-5G6CZH3): /proc/driver/nvidia/version does not exist\n",
      "2022-03-21 11:53:56.173523: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0326edd3-cf92-4f63-9e8f-b1f3f88638a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a strategy scope.\n",
    "# with strategy.scope():\n",
    "#     # Everything that creates variables should be under the strategy scope.\n",
    "#     # In general this is only model construction & `compile()`.\n",
    "#     model = get_compiled_model()\n",
    "\n",
    "# # Train the model on all available devices.\n",
    "# train_dataset, val_dataset, test_dataset = get_dataset()\n",
    "# model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n",
    "\n",
    "# # Test the model on all available devices.\n",
    "# model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb32fc-bfa8-4c07-833a-5396b2669365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d07bcb0-83e6-43c8-a5af-0dac1b9648f7",
   "metadata": {},
   "source": [
    "## Fault tolerance\n",
    "\n",
    "Use Model Checkpointing (saw in the previous lesson) to be able to recover a model from a previous epoch if the training fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a29a7b-72dd-4a2d-af80-050d9b12cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = f\"{os.getcwd()}/../models/checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea4247cd-0437-485d-8573-4065b184bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return tf.keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75bd8693-4030-4377-8a31-9353ca16f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(epochs=1):\n",
    "    # Create a MirroredStrategy.\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    # Open a strategy scope and create/restore the model\n",
    "    with strategy.scope():\n",
    "        model = make_or_restore_model()\n",
    "\n",
    "    callbacks = [\n",
    "        # This callback saves a SavedModel every epoch\n",
    "        # We include the current epoch in the folder name.\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_dir + \"/checkpoint-{epoch}\", \n",
    "            save_freq=\"epoch\"\n",
    "        )\n",
    "    ]\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_dataset,\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f130ba34-677b-4174-99ff-2c25ee6e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running the first time creates the model\n",
    "# run_training(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0a5a88-1c84-4e84-9823-efc99fbb02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calling the same function again will resume from where we left off\n",
    "# run_training(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e01106-113f-43d2-8bce-52b02245faf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04bc93ce-77d4-4c0c-a4c0-12f08ca0a9d9",
   "metadata": {},
   "source": [
    "### Dataset caching\n",
    "\n",
    "Add data caching to an example\n",
    "\n",
    "and\n",
    "\n",
    "### Prefetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3b9de-7403-4f18-a4da-721567b8e14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec6be9-0817-46b3-bc33-04bd394b72a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b29d0-5709-48be-9901-16722e4fa7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e178d-9b5d-4096-b522-b6b7801ad75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c24c725f-0aed-4b26-b2c0-6e02de0ad324",
   "metadata": {},
   "source": [
    "Examples of how to distribute deep learning on a High Performance Computer (HPC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e0511-23ec-4f5a-a866-228bae6fd60c",
   "metadata": {},
   "source": [
    "## Install Python environments\n",
    "\n",
    "First, install the Python environments for the required HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d909d3-abf8-4531-b680-33d8a7db48d7",
   "metadata": {},
   "source": [
    "## ARC4\n",
    "\n",
    "### Miniconda installer\n",
    "```bash\n",
    "# download miniconda (x86_64 for ARC4)\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    "# run miniconda, read terms, and set path\n",
    ". Miniconda3-latest-Linux-x86_64.sh\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "# clone - tensorflow 2.7.0 and ray\n",
    "conda env create --file tf_ray_arc4.yml\n",
    "\n",
    "# clone - pytorch 1.10 and ray\n",
    "module load gnu/8.3.0\n",
    "conda env create --file pytorch_ray_arc4.yml\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "# create new - tensorflow 2.7.0 and ray\n",
    "conda create -n tf_ray_arc4 -c conda-forge python==3.9.* cudatoolkit==11.2.* cudnn==8.1.*\n",
    "conda activate tf_ray_arc4\n",
    "pip install -U pip\n",
    "pip install tensorflow==2.7.0\n",
    "pip install -U ray\n",
    "pip install -U ray[tune]\n",
    "\n",
    "# create new - pytorch (1.10) and ray\n",
    "module load gnu/8.3.0\n",
    "conda create -n pytorch_ray_arc4 pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "conda activate pytorch_ray_arc4\n",
    "pip install -U ray\n",
    "pip install -U ray[tune]\n",
    "\n",
    "# create new - jax\n",
    "conda create -n jax python=3.8 cudatoolkit=11.2 cudatoolkit-dev=11.2 cudnn=8.2\n",
    "conda activate jax\n",
    "pip install -U jax\n",
    "pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b51ba4-6980-4d56-976f-5bffd854751d",
   "metadata": {},
   "source": [
    "## Bede\n",
    "\n",
    "### Miniconda installer\n",
    "```bash\n",
    "# Replace <project> with your project code\n",
    "export DIR=/nobackup/projects/<project>/$USER\n",
    "\n",
    "# download miniconda (ppc64le for Bede's hardware, not x86_64 as for ARC4)\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-ppc64le.sh\n",
    " \n",
    "# run miniconda\n",
    "sh Miniconda3-latest-Linux-ppc64le.sh -b -p $DIR/miniconda\n",
    "source miniconda/bin/activate\n",
    " \n",
    "# update conda and set channels\n",
    "conda update conda -y\n",
    "conda config --prepend channels conda-forge\n",
    "conda config --prepend channels https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\n",
    "conda config --prepend channels https://opence.mit.edu\n",
    "```\n",
    "\n",
    "This is what my `~/.condarc` ends up as:\n",
    "```bash\n",
    "channel_priority: flexible\n",
    "channels:\n",
    "  - https://opence.mit.edu\n",
    "  - https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "# clone - tensorflow 2.7.0 and ray\n",
    "conda env create --file tf_bede.yml\n",
    "\n",
    "# clone - pytorch 1.10 and ray\n",
    "conda env create --file pytorch_bede.yml\n",
    "\n",
    "# clone - pytorch 1.9.0, cuda 10.2, and pytorch_geometric 2.0.3\n",
    "module load gcc # require this for some of the libraries\n",
    "conda env create --file pytorch_geometric_bede.yml\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "# create an environment for pytorch\n",
    "conda create -n pytorch pytorch torchvision cudatoolkit=10.2\n",
    " \n",
    "# create an environment for tensorflow\n",
    "conda create -n tf tensorflow\n",
    "\n",
    "# create an environment for pytorch geometric\n",
    "module load gcc\n",
    "conda create -n pytorch_geometric pytorch cudatoolkit=10.2\n",
    "conda activate pytorch_geometric\n",
    "\n",
    "pip install torch-scatter\n",
    "pip install torch-sparse\n",
    "pip install torch-geometric\n",
    "pip install torch-cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731aab36-d5bb-4c5d-bece-ec21783dd7fa",
   "metadata": {},
   "source": [
    "## JADE-2\n",
    "\n",
    "### Miniconda installer\n",
    "\n",
    "```bash\n",
    "...\n",
    "```\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "#### Clone pre-created environments\n",
    "\n",
    "```bash\n",
    "...\n",
    "```\n",
    "\n",
    "#### Create your own\n",
    "\n",
    "```bash\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ea8d1-52a9-4085-9008-10d1dd60ed15",
   "metadata": {},
   "source": [
    "## Jupyter Notebook to HPC\n",
    "\n",
    "It's preferable to use a static job on the HPC. To do this, you could test out different ideas locally in a Jupyter Notebook, then when ready convert this to an executable script (`.py`) and move it over. \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cfd64-4afb-4e03-8712-3d9935879e91",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "These examples use [Ray Train](https://docs.ray.io/en/latest/train/train.html) in a static job on a HPC.\n",
    "Ray handles most of the complexity of distributing the work, with minimal changes to your [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) or [PyTorch](https://pytorch.org/tutorials/beginner/dist_overview.html) code.\n",
    "\n",
    "- Python script examples:\n",
    "  - TensorFlow\n",
    "    - MNIST end-to-end: [`tensorflow_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/tensorflow_mnist_example.py).  \n",
    "    - MNIST tuning: [`tensorflow_tune_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/tensorflow_tune_mnist_example.py).  \n",
    "    - Train linear model with Ray Datasets: [`tensorflow_linear_dataset_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/tensorflow_linear_dataset_example.py).  \n",
    "  - PyTorch\n",
    "    - Linear: [`pytorch_train_linear_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/pytorch_train_linear_example.py).  \n",
    "    - Fashion MNIST: [`pytorch_train_fashion_mnist_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/pytorch_train_fashion_mnist_example.py).  \n",
    "    - HuggingFace Transformer: [`pytorch_transformers_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/pytorch_transformers_example.py).  \n",
    "    - Tune linear model with Ray Datasets: [`pytorch_tune_linear_dataset_example.py`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/pytorch_tune_linear_dataset_example.py).  \n",
    "- Then submit the job to HPC (choose one and update the Python script within it):\n",
    "  - [ARC4](https://arcdocs.leeds.ac.uk/systems/arc4.html) (SGE)  \n",
    "    - CPU: [`ray_train_on_arc4_cpu.bash`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/ray_train_on_arc4_cpu.bash).  \n",
    "    - GPU: [`ray_train_on_arc4_gpu.bash`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/ray_train_on_arc4_gpu.bash).  \n",
    "  - [Bede](https://bede-documentation.readthedocs.io/en/latest/) (SLURM)\n",
    "    - GPU: [`ray_train_on_bede.bash`](https://github.com/lukeconibear/intro_ml/blob/main/distributed/ray_train_on_bede.bash).  \n",
    "  - [JADE-2](http://docs.jade.ac.uk/en/latest/index.html) (SLURM)\n",
    "    - GPU: ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fbf5b-68db-4b0f-b274-2c02cf2921a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ba867-497b-49da-9365-8ec52064aff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b6c73-a7ea-4e53-a2cf-0d1294aa5daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aad8c-4514-4652-b8ec-59807a8c1056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "172846d1-c075-4cfd-81f4-7401dd0135e7",
   "metadata": {},
   "source": [
    "https://keras.io/guides/distributed_training/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4ca1f-42f4-4e7c-bb38-73c30401fc66",
   "metadata": {},
   "source": [
    "Synchronous data-parallel training on all available GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b487b5-a8d6-421a-831b-c2fab2f09d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_strategy = tf.distribute.MirrorStratergy()\n",
    "# with distribution_strategy.scope():\n",
    "#     # Everything that creates variables should be under the strategy scope.\n",
    "#     # In general this is only model construction and compile()\n",
    "#     model = build_model()\n",
    "#     model.compile(optimiser, loss)\n",
    "#     model.fit(dataset, epochs=epochs, callbacks=callbacks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d227b3f-2910-4d3b-82bb-8ab241cc1772",
   "metadata": {},
   "source": [
    "should the `model.fit` call be inside or outside the scope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b677227-469f-4b11-8ae9-9d8b6c562264",
   "metadata": {},
   "source": [
    "#$ -cwd\n",
    "\n",
    "not\n",
    "\n",
    "#$ -cwd -V\n",
    "\n",
    "so have to specific the reproducible environment with the job submission (not copied over from the terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e991d8-5171-4a24-908c-1aae5016bf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa82c005-5721-434c-a8c7-d5eb5f2f2afb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f161fc-1a28-4b12-9fe8-fad13ff441bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a813e565-680a-48c9-94e7-b97a584bec20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754aab4-d77f-49ba-99e3-459db572bb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3974fe93-af71-489f-926d-67d542b2f869",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1a84b-3d74-4bab-8d2d-5eaa08fadb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027f592-a249-41cf-bff5-6e842e358f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfa02a-60cf-4e35-946c-d6d90dd6c44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafbd9b-1ac6-4017-9e13-63b734862265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd26db-3e9d-4ada-8b60-ec674b674b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <distributed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Batch the dataset with the global batch size e.g., for 8 devices each capable of a btach of 64 use the global batch size of 512 (= 8 * 64).  \n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [Horovod](https://horovod.ai/)\n",
    "- [DeepSpeed](https://www.deepspeed.ai/)\n",
    " \n",
    "### Resources\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebad9cd-bc43-4281-8729-06e7650fefee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
