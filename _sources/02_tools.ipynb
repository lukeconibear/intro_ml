{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/01_fundamentals.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6ab59-beef-4250-91c9-e56328a17e00",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "There is huge variety of machine learning and deep learning tools.\n",
    "\n",
    "In this course, we'll focus on:\n",
    "\n",
    "- [scikit-learn](scikit-learn)\n",
    "- [TensorFlow](tensorflow)\n",
    "- [PyTorch](pytorch)\n",
    "\n",
    "The tool you choose depends on:\n",
    "\n",
    "- Your research problem\n",
    "- Model availability (e.g., pre-trained, state-of-the-art)\n",
    "- Deployment (e.g., hardware)\n",
    "- Ecosystem (e.g., compatibility with other tools)\n",
    "- Personal preferences\n",
    "\n",
    "There are many discussions on the different choices e.g., [1](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/), [2](https://keras.io/why_keras/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442514c-57d4-4923-896d-8edbb4b5d08e",
   "metadata": {},
   "source": [
    "(scikit-learn)=\n",
    "### [scikit-learn](https://scikit-learn.org/stable/)\n",
    "\n",
    "Scikit-learn has a wide range of simple and efficient machine learning tools.  \n",
    "\n",
    "- [Documentation](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [Tutorials](https://scikit-learn.org/stable/tutorial/index.html)\n",
    "- [Examples](https://scikit-learn.org/stable/auto_examples/index.html)\n",
    "\n",
    "There are ones for:\n",
    "\n",
    "- [Linear models](https://scikit-learn.org/stable/modules/linear_model.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#generalized-linear-models))\n",
    "- [Nearest neighbours](https://scikit-learn.org/stable/modules/neighbors.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#nearest-neighbors))\n",
    "- [Support vector machines](https://scikit-learn.org/stable/modules/svm.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#support-vector-machines))\n",
    "- [Decision trees](https://scikit-learn.org/stable/modules/tree.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#decision-trees))\n",
    "- And [many more](https://scikit-learn.org/stable/index.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732b640-656f-4dff-a83a-173b4cbadc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "(tensorflow)=\n",
    "### [TensorFlow](https://www.tensorflow.org/)\n",
    "\n",
    "Tensorflow is an end-to-end open source machine learning platform.\n",
    "\n",
    "- [Documentation](https://www.tensorflow.org/guide)\n",
    "- [Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [Examples](https://keras.io/examples/)\n",
    "\n",
    "TensorFlow has use-friendly higher-level APIs (Application Programming Interface):\n",
    "\n",
    "- [Keras](https://keras.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f618cc7-107a-46a5-9596-3fb9dad8b224",
   "metadata": {},
   "source": [
    "Keras includes a wide range of high-level objects including:\n",
    "\n",
    "- [Models](https://keras.io/api/models/)\n",
    "- [Layers](https://keras.io/api/layers/)\n",
    "    - [Activations](https://keras.io/api/layers/activations) e.g., sigmoid\n",
    "    - [Weight initialisers](https://keras.io/api/layers/initializers/) e.g., HeNormal\n",
    "    - [Regularisers](https://keras.io/api/layers/regularizers/) e.g., L2\n",
    "    - [Convolutional](https://keras.io/api/layers/convolution_layers/) e.g., Conv2D\n",
    "    - [Pooling](https://keras.io/api/layers/pooling_layers/) e.g., MaxPooling2D\n",
    "    - [Recurrent](https://keras.io/api/layers/recurrent_layers/) e.g., LSTM (long-short-term-memory)\n",
    "    - [Preprocessing](https://keras.io/api/layers/preprocessing_layers/) e.g., vectorisation\n",
    "- [Optimisers](https://keras.io/api/optimizers/) e.g., Adam\n",
    "- [Losses](https://keras.io/api/losses/) e.g., MeanSquaredError\n",
    "- [Metrics](https://keras.io/api/metrics/) e.g., Accuracy\n",
    "\n",
    "\n",
    "You can always go to the lower-level API, which is useful for custom objects.\n",
    "\n",
    "- [Model subclassing](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html)\n",
    "    - Similar to PyTorch\n",
    "- [Automatic differention](https://www.tensorflow.org/guide/autodiff) with `tf.GradientTape()`  \n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bec0e-7d4e-43ba-91db-b1af0af99863",
   "metadata": {},
   "source": [
    "There are many [libraries and extensions](https://www.tensorflow.org/resources/libraries-extensions) including:\n",
    "\n",
    "- [TensorFlow Extended](https://www.tensorflow.org/tfx) for deployment.\n",
    "- [TensorFlow Lite](https://www.tensorflow.org/lite/guide) for mobile and IoT (internet of things) devices.\n",
    "- [TensorBoard](https://www.tensorflow.org/tensorboard) for visualising the experiment results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d870831-803d-410f-942e-8552e7900844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "A model consists of many layers.\n",
    "\n",
    "Each layer is an input-output transformation.\n",
    "\n",
    "These models and layers can be built using either of these API (application programming interface):\n",
    "\n",
    "| [Sequential](https://keras.io/guides/sequential_model/) | [Functional](https://keras.io/guides/functional_api/) | [Subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models/) |\n",
    "| --- | --- | --- |\n",
    "| Linear stack of layers. | Non-linear DAG (directed acyclic graph) of layers (can be shared). | Similar to Functional, except uses subclasses. | \n",
    "| Each layer has one input and one output. | Each layer can have multiple inputs and outputs. |\n",
    "\n",
    "Hence, the Sequential API is simpler and the Functional API is more flexible and suitable for complicated models. While the Functional and Subclassing options are similar and mainly a taste preference for those that like object-orientated code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676c92f-d0a2-4e16-bc4d-ef5043525533",
   "metadata": {},
   "source": [
    "(pytorch)=\n",
    "### [PyTorch](https://pytorch.org/)\n",
    "\n",
    "PyTorch is an end-to-end open source machine learning platform.\n",
    "\n",
    "- [Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- [Tutorials](https://pytorch.org/tutorials/)\n",
    "\n",
    "PyTorch has use-friendly higher-level APIs:\n",
    "\n",
    "- [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/)\n",
    "    - Helps write boilerplate code, scale out to multiple devices, and other helpful things.\n",
    "\n",
    "You can always go to the lower-level API, which is useful for custom objects.\n",
    "\n",
    "- ...\n",
    "\n",
    "\n",
    "There are many [libraries and extensions](https://pytorch.org/ecosystem/) including:\n",
    "\n",
    "- [TorchServe](https://pytorch.org/serve/) for deployment.\n",
    "- [Pytorch Live](https://pytorch.org/live/) for mobile and IoT devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2070596-7cec-42b2-8fa5-884dcaa9ee2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12f3b5c7-f520-49db-94f9-6056d8132131",
   "metadata": {},
   "source": [
    "## Example - Linear regression\n",
    "\n",
    "Let's start with a simple example fitting a straight line to data.\n",
    "\n",
    "We'll see how this in done in each of three key tools we cover here: scikit-learn, TensorFlow, and PyTorch.\n",
    "\n",
    "Let's create some (noisy) data to train on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da44fa9-d46c-40d4-9f7f-954d2364ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd737f-57a5-4387-9f24-2b8a9833e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_linear_data(num_points):\n",
    "    x = np.arange(num_points)\n",
    "    noise = np.random.normal(0, 1, num_points)\n",
    "    y = 2 * x + noise\n",
    "    # convert to 2D arrays\n",
    "    x, y = x.reshape(-1, 1), y.reshape(-1, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6009ddc-563d-4c4f-8e26-453dd2794d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_noisy_linear_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cf489-406c-4283-bba1-3daf9febaf41",
   "metadata": {},
   "source": [
    "```{caution} \n",
    "\n",
    "Input arrays to models needs to be 2 dimensional (2D) i.e., a column of rows.\n",
    "\n",
    "For example, instead of one row:\n",
    "\n",
    "`>>> np.arange(10)`  \n",
    "`array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])`  \n",
    "\n",
    "Convert this to a column of rows using `.reshape(-1, 1)`:  \n",
    "\n",
    "`>>> np.arange(10).reshape(-1, 1)`  \n",
    "`array([[0],`  \n",
    "`       [1],`  \n",
    "`       [2],`  \n",
    "`       [3],`  \n",
    "`       [4],`  \n",
    "`       [5],`  \n",
    "`       [6],`  \n",
    "`       [7],`  \n",
    "`       [8],`  \n",
    "`       [9]])`  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4da99-a120-4a3d-8b48-1c79042662f7",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "First, let's try with [scikit-learn](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3cce2-5397-4a8f-8a57-0998dd883595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d9bd8-647e-48ca-b008-9fe731bcad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb6d28-d60b-44a0-904e-d888c27ab0cb",
   "metadata": {},
   "source": [
    "When fit is called for Linear Regression, the _loss_ that is trying to be minimised is the _mean squared error_ between the predictions and the actual values.\n",
    "\n",
    "This determines what parameters the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc66adf-083e-4756-8658-2525a5da3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd999b8-57fa-4abd-b680-a65df7ecd28d",
   "metadata": {},
   "source": [
    "The data was from the line `y = 2x`, so the gradient was 2.\n",
    "\n",
    "Let's see what the model estimated it to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bc2f4-40e8-4e2e-900a-1a04b478381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = model_sklearn.coef_[0]\n",
    "intercept = model_sklearn.intercept_\n",
    "\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ffc9d-d04e-4290-a506-82d65c82f1a2",
   "metadata": {},
   "source": [
    "Pretty close, considering there was only 10 training data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abb76f-86c2-41ca-85f9-1252c2865af9",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now, for **TensorFlow**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28b86a-b5f7-4633-8ce0-3b727a305ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c857048-a87e-4c09-be4f-1c19c42873a1",
   "metadata": {},
   "source": [
    "Create the model.\n",
    "\n",
    "It's helpful to name the layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db868b2c-1210-465f-8ad7-5250cba5912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(1,), name=\"inputs\"),\n",
    "        tf.keras.layers.Dense(units=1, name=\"outputs\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c425145-2112-4d46-a82a-d1f1c5706c15",
   "metadata": {},
   "source": [
    "You can now show the model summary.\n",
    "\n",
    "Note, this only shows layers (not the `Input` object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0f3c4-e904-42c0-bd66-a2ee977e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eff5e2-f317-4592-96fa-165dd9365d20",
   "metadata": {},
   "source": [
    "You can also show the model graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e86528-b426-4dc0-aeff-656dc0f9ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_tf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e30465-c014-4d78-a9e5-05a20ead1700",
   "metadata": {},
   "source": [
    "Now, compile the model.\n",
    "\n",
    "The keyword arguments to `optimizer`, `loss`, and `metrics` can either be strings (e.g., `mean_squared_error`) or TensorFlow objects (e.g., `tf.keras.metrics.mean_squared_error`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e416f-5a3b-4d8e-87e0-63cd2dd72374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    optimizer=\"sgd\",  # how to reduce the loss\n",
    "    loss=\"mean_squared_error\",  # what to minimise (i.e., proxy for metric)\n",
    "    metrics=[\"accuracy\"],  # what actually care about\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4985a4-dcd7-45ca-816c-bbf82b154cd0",
   "metadata": {},
   "source": [
    "And, train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334c6ea-749c-487a-93eb-33c41ab83360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.fit(\n",
    "    x_train,\n",
    "    y_train,  # the training data\n",
    "    epochs=10,  # how many runs through the training data\n",
    "    verbose=False,  # print out the metrics per epoch\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11842bb-ef87-4abe-9d3d-60a4c693220f",
   "metadata": {},
   "source": [
    "And, let's see what this model though the gradient was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffed94-249f-4c44-bfc3-c97da42582aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.weights[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f8d7a-f9eb-49f3-9bf0-dd33ba6d497c",
   "metadata": {},
   "source": [
    "Now, we can see how well these models fit a line to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cca24-c4b4-4c40-8e67-328984c085b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = model_sklearn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97e974-9aee-459e-9a02-4e4f6decc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tf = model_tf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c466f2e-0499-432d-8261-a0387a73cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = {\"font.size\": 14, \"text.usetex\": True}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e07cf1-ce8c-43b2-b4f4-a8dbe1ec671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"data\": \"#1b9e77\", \"sklearn\": \"#d95f02\", \"tf\": \"#7570b3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8b976-b330-4e80-ab28-c44949a47a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(8, 4))\n",
    "ax1, ax2 = fig.subplots(1, 2)\n",
    "\n",
    "ax1.scatter(x_train, y_train, color=colors[\"data\"])\n",
    "ax1.plot(x_train, y_pred_sklearn, color=colors[\"sklearn\"], linewidth=3)\n",
    "ax1.set_title(\"scikit-learn model\")\n",
    "\n",
    "ax2.scatter(x_train, y_train, color=colors[\"data\"])\n",
    "ax2.plot(x_train, y_pred_tf, color=colors[\"tf\"], linewidth=3)\n",
    "ax2.set_title(\"TensorFlow model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a49675-0fe2-4865-bcc0-0dff3e3ff65e",
   "metadata": {},
   "source": [
    "They both did a good job of fitting a function to the data.\n",
    "\n",
    "In other words, they found the association in the data.\n",
    "\n",
    "However, this was a very simple example that probably didn't require machine learning (let alone deep learning).\n",
    "\n",
    "Though it demonstrates what they do.\n",
    "\n",
    "Now, let's look at something a little more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b64ae5-3e08-46e1-b00d-634a0f81fab8",
   "metadata": {},
   "source": [
    "## Example - Digit classification\n",
    "\n",
    "Let's train a model to recognise digits.\n",
    "\n",
    "This is a classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f12ea-a578-43ec-9b00-9960b48a5918",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "First, with [scikit-learn](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504041c-e6f1-4555-8a70-4397f224ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c3bab-6c75-4da1-913d-9b92d8c4f780",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f933f0-c80d-4e3f-9a38-6cb08aa1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651945d-76aa-4344-943a-aa969d334f71",
   "metadata": {},
   "source": [
    "Take a look at the labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a005238-5e98-402c-9590-03ce0e28be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d83c6-6527-4eca-b7fc-23e34aa97293",
   "metadata": {},
   "source": [
    "#### Preprocess and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba99d9-5ea0-489f-86e6-e7d1c8d9db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(digits):\n",
    "    # the data comes as 2D 8x8 pixels\n",
    "    # flatten the images to 1D 64 pixels\n",
    "    n_samples = len(digits.images)\n",
    "    data = digits.images.reshape((n_samples, -1))\n",
    "    return n_samples, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e28ca8-5e7f-4633-bb70-9a88bc6e33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, data = preprocess_data(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aea168-cc0c-4729-8c19-7374a3a5d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd6e41-d69d-4b57-baf5-fb2c4978de78",
   "metadata": {},
   "source": [
    "#### Create a model\n",
    "\n",
    "Here, we will use a [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) (a type of support vector machine).\n",
    "\n",
    "This model focuses on the two hardest to classify examples and places support vectors between them to form the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed26cc-1768-4392-8438-8d10cb4aa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce02572-5b4b-4d24-bd06-e592f4b608b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2234a-bfd9-42af-8ed5-430b7149df0f",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025a658-a6fa-4619-a7c0-1be95d468968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff8a3f-d7f7-4d52-b5b8-19f655df8a24",
   "metadata": {},
   "source": [
    "#### Use the model to predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7866281-7779-4b92-bf03-ca65647a62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb390b74-03d8-4569-876b-e19886d3bd79",
   "metadata": {},
   "source": [
    "Take a look at the predictions for these test digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dc823-dff0-4d8c-b23b-4415438eb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)  # 1D 64 pixels to 2D 8*8 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a01b1a-401e-4e7a-9590-3165cd5ad85f",
   "metadata": {},
   "source": [
    "#### How well did our model do overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c9975-5085-423c-9705-cc30db06fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789c732-9197-42b1-a5a0-1b144b8e51af",
   "metadata": {},
   "source": [
    "97% accuracy is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fab801-a015-4a6a-8b18-2c6e2d57c138",
   "metadata": {},
   "source": [
    "Let's do some quick error analysis using a [confusion matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).\n",
    "\n",
    "This shows how well the classification model did for each category.\n",
    "\n",
    "The predictions are on the x-axis and the true labels from the test data are on the y-axis.\n",
    "\n",
    "A perfect score would be where the predictions always match the true labels (i.e., all values are on the diagonal line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39735d-09c6-4f19-a0df-93673a8a6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "confusion_matrix.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bd0ae-5631-4a3e-9531-116f8f2c4190",
   "metadata": {},
   "source": [
    "We can see that the although the model did well, it struggled with 3's by confusing them with 5's, 7's, and 8's.\n",
    "\n",
    "This points us in the direction of how we might improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7be2e0-c543-4f94-a9ef-8bad75d972db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400193db-2523-4878-8944-53d2810c3214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7fc53b-e1a4-4f8e-8412-716ae8908485",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f79f22-a60e-4aa9-83b9-5534ec69020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa733f-e4f6-44fe-aa7d-8bf32fe2b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7dd2dc-9051-4e2c-8035-3db8e7498767",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = cross_val_score(model, X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9350fd-e46b-461d-b61b-f3a32a0d0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b8d0b-0cd1-4846-ac3c-e6635f035fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CV accuracy = {test_scores.mean():0.2f} (+/- {test_scores.std():0.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e32e-a49f-4ac4-9fe0-1a2ef4fd4e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e4df9c-bf68-41cf-a34f-a7e95b615de8",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f64c2-e95e-4175-92a8-27e934e8cf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bc8175-beed-44b3-9b96-cb8743f87fb3",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now, with [TensorFlow](https://www.tensorflow.org/datasets/keras_example):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75afe544-9b97-44cc-9037-72f0b1cfc3a6",
   "metadata": {},
   "source": [
    "Check whether there are any [GPUs](https://www.tensorflow.org/guide/gpu) available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee3b3cc-0d98-4f54-bf8e-b6bfed74c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 18:05:08.557713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-22 18:05:08.557734: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-22 18:05:08.557760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (UOL-LAP-5G6CZH3): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244e268-847e-462b-9215-c39d1f967e8e",
   "metadata": {},
   "source": [
    "#### Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3086bf5-2d57-4039-835e-a69e6d1ddd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab06ce2-cba5-4ba8-9cdb-1a11565bd43c",
   "metadata": {},
   "source": [
    "Take a look at some of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642e6699-8438-42eb-b487-ef803ea6ca86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax, image, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes, train_images, train_labels):\n\u001b[1;32m      3\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_axis_off()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, train_images, train_labels):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(28, 28)  # 1D 784 pixels to 2D 28*28 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640b7bf-ae9f-40d9-8506-6929dd9016c5",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f798985-464c-4aac-a422-66e2fd43cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = tf.keras.layers.Flatten()(data)  # flatten the 2D image to a 1D tensor\n",
    "    data = tf.keras.layers.Rescaling(1.0 / 255)(\n",
    "        data\n",
    "    )  # normalise the images to greyscale\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba08341f-77df-4a44-a9da-def4a55d5531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 18:05:15.308405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_images = preprocess_data(train_images)\n",
    "test_images = preprocess_data(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4240e6-e735-40c3-acde-b9243ce84e16",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "\n",
    "Can use any of the sequential, functional, or subclassing APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dca4fd-c2e6-497c-89f2-583c040b16d6",
   "metadata": {},
   "source": [
    "[Sequential API](https://keras.io/guides/sequential_model/)\n",
    "\n",
    "Note, you could also use many `.add()` calls instead of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f011921-a2e8-4e55-9d23-43bb545ab5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 128)               100480    \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 128)               16512     \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(784,), name=\"inputs\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputs\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2242a7-c9aa-4dc9-aaaf-d512979fbf93",
   "metadata": {},
   "source": [
    "[Functional API](https://keras.io/guides/functional_api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a8484d2-9883-46d1-9cc0-8d97d42fe239",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(784,), name=\"inputs\")\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputs\")(x)\n",
    "\n",
    "model_functional = tf.keras.Model(inputs, outputs, name=\"functional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aed69d-7f03-4f99-bba5-6abed32d8a67",
   "metadata": {},
   "source": [
    "[Subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models/)\n",
    "\n",
    "Note, you can visualise Subclassed models via the guidance [here](https://github.com/tensorflow/tensorflow/issues/31647#issuecomment-692586409)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d45d93cc-fb95-4ba3-a77a-ac4db94e3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, name=\"subclassing\"):\n",
    "        super(MyModel, self).__init__(name=name)\n",
    "        self.layer1 = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")\n",
    "        self.layer2 = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")\n",
    "        self.outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputs\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        return self.outputs(x)\n",
    "    \n",
    "model_subclassing = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f97456-7cc1-498b-ae48-df93616be68a",
   "metadata": {},
   "source": [
    "Let's use the simpler Sequential API for now.\n",
    "\n",
    "We can now also visualise the architecure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d92fbd72-88c1-4cad-858a-ef72c619ed15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16066285-560f-4a97-81fe-8fc406763b6f",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "It's useful to name the metrics, especially if there's more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "626bbe3c-a8e9-41cb-a31b-64612c51fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c0668-dd78-4d12-aae1-0c213a118868",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data\n",
    "\n",
    "The `fit()` call returns a `history` object.\n",
    "\n",
    "Note, the `validation_split` keyword argument can only be used for NumPy training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e07edd-d5b0-4521-bafc-4abbc734ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=2,  # how many runs through the data\n",
    "    batch_size=64,  # how many samples in each batch\n",
    "    verbose=False,  # print the output from each epoch\n",
    "    validation_split=0.2,  # automatically set apart a validation set: 0.2 means 20% for validation\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d6d64-e533-490a-a339-3d862a305dff",
   "metadata": {},
   "source": [
    "The `history.history` dictionary then contains the loss and metrics per epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351826c-b478-48f0-9db1-3c3391233193",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31481e-bb0e-477f-9dc7-9a166a9e203d",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "\n",
    "Use the model for predictions with [`model.predict()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) (i.e., inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2506b73-053f-4105-acbb-686481e7270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdb0fd-b334-4aab-be2d-624d33b03c5d",
   "metadata": {},
   "source": [
    "Each prediction has a probability per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b86d-09e5-41d7-8643-0d05b76667e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367c9f2-0e38-4a5c-9593-dff8a03be740",
   "metadata": {},
   "source": [
    "The most likely category can be found by finding the maximum of these (using [`np.argmax`](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c959-777c-4782-a0f5-498e41db74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b45b84-3882-431c-bcfb-9c0f4ded9742",
   "metadata": {},
   "source": [
    "So, the model things the first digit is a 7.\n",
    "\n",
    "Let's plot the first four test digits with their predictions to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df94d9-7b07-43ea-b458-6b6bae27bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, test_images, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = tf.reshape(image, (28, 28))  # 1D 784 pixels to 2D 28*28 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {np.argmax(prediction):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902a6c3-b4e2-4007-beae-c05bb3c7c246",
   "metadata": {},
   "source": [
    "#### Let's now evaluate the model overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d338cb-f408-4d84-bdc8-471aa6d006b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy (R2): {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64b48a-92ed-41ac-8191-24986b0eb0b5",
   "metadata": {},
   "source": [
    "Similar to scikit-learn an overall accuracy of 98% is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e71b3-13a5-44c4-8e20-7cb023826263",
   "metadata": {},
   "source": [
    "A before, let's have a look at a confusion matrix for this.\n",
    "\n",
    "_TensorFlow does have its own [`confusion_matrix`](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix) method. Though I'll use the scikit-learn one here again as it has a nice plot feature._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59296f-6c03-41e2-b2df-fdb228ec677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    test_labels, np.argmax(y_pred, axis=1)\n",
    ")\n",
    "confusion_matrix.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373598e-833b-4367-915d-200b3f19f68f",
   "metadata": {},
   "source": [
    "This model did well for most digits, though struggled a bit with 5's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987aadde-3f0f-48b1-bccf-029d85118673",
   "metadata": {},
   "source": [
    "#### Save the model\n",
    "\n",
    "A model includes:\n",
    "\n",
    "- Architecture\n",
    "- Weights (i.e., state)\n",
    "- Configuration (e.g., optimiser, loss, metrics)\n",
    "\n",
    "Can save the whole or parts.\n",
    "\n",
    "Formats:\n",
    "\n",
    "- [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model): single archive (recommended)\n",
    "    - Save: `model.save()` or `tf.keras.models.save_model()`\n",
    "    - Load: `tf.keras.models.load_model()`\n",
    "    - Keras H5 was the older format\n",
    "- Architecture only (JSON)\n",
    "    - Save: `get_config()` and `tf.keras.models.model_to_json()`\n",
    "    - Load: `from_config()` and `tf.keras.models.model_from_json()`\n",
    "- Weights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68540d-7fec-4ac0-a6fe-f8c9464116e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_models = f\"{os.getcwd()}/../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8bb69-bc13-45ff-86ac-aa5b04dd38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{path_models}/model_tf_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3a91-42a2-43d7-9445-7cd1687ba4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path_models}/model_tf_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72cb63-551f-4b31-86d3-7dafade79431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <tools>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970bc04-88fc-4cf2-89b3-7b4cdc8bc1f8",
   "metadata": {},
   "source": [
    "## Further information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b8126-a770-470e-af61-023eea1593fa",
   "metadata": {},
   "source": [
    "### Good practices\n",
    "\n",
    "- Debugging: \n",
    "    - Test each part individually, before testing the whole.\n",
    "    - Check the model summary and visualise the architecture.\n",
    "    - Use debug modes (e.g., add `run_eagerly=True` with the call to `fit()` in Keras.)\n",
    "    - Tips for [Keras](https://keras.io/examples/keras_recipes/debugging_tips/).\n",
    "- Offloading computations to a GPU may not be beneficial for small models.\n",
    "- Tips for optimising GPU performance from [TensorFlow](https://www.tensorflow.org/guide/gpu_performance_analysis), [NVIDIA](https://docs.nvidia.com/deeplearning/performance/index.html).\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Other options\n",
    "\n",
    "There are many other options, including:\n",
    "\n",
    "- [JAX](https://jax.readthedocs.io/en/latest/#)\n",
    "    - A library for GPU accelerated NumPy with automatic differentiation.\n",
    "- [Flax](https://github.com/google/flax)\n",
    "    - A neural network library and ecosystem for JAX that is designed for flexibility.\n",
    "- [Haiku](https://dm-haiku.readthedocs.io/en/latest/)\n",
    "    - Built on top of JAX to provide simple, composable abstractions for machine learning research.\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/stable/)\n",
    "    - Gradient boosting library.\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/)\n",
    "    - Gradient boosting library.\n",
    "- [Caffe](https://caffe.berkeleyvision.org/)\n",
    "    - Deep learning framework.\n",
    "- [Sonnet](https://sonnet.readthedocs.io/en/latest/)\n",
    "    - High-level API for TensorFlow.\n",
    "- [fastai](https://docs.fast.ai/)\n",
    "    - High-level API for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c5a0f-2f82-441c-9097-32417fff0152",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464fb29-b07b-488a-8d56-fa0d0452a2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
