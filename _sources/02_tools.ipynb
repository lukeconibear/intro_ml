{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/02_tools.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6ab59-beef-4250-91c9-e56328a17e00",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "There is huge variety of machine learning and deep learning tools.\n",
    "\n",
    "In this course, we'll focus on:\n",
    "\n",
    "- [scikit-learn](scikit-learn)\n",
    "- [TensorFlow](tensorflow)\n",
    "- [PyTorch](pytorch)\n",
    "\n",
    "The tool you choose depends on:\n",
    "\n",
    "- Your research problem\n",
    "- Model availability (e.g., pre-trained, state-of-the-art)\n",
    "- Deployment (e.g., hardware)\n",
    "- Ecosystem (e.g., compatibility with other tools)\n",
    "- Personal preferences\n",
    "\n",
    "There are many discussions on the different choices e.g., [1](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/), [2](https://keras.io/why_keras/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442514c-57d4-4923-896d-8edbb4b5d08e",
   "metadata": {},
   "source": [
    "(scikit-learn)=\n",
    "### [scikit-learn](https://scikit-learn.org/stable/)\n",
    "\n",
    "Scikit-learn has a wide range of simple and efficient machine learning tools.  \n",
    "\n",
    "- [Documentation](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [Tutorials](https://scikit-learn.org/stable/tutorial/index.html)\n",
    "- [Examples](https://scikit-learn.org/stable/auto_examples/index.html)\n",
    "\n",
    "There are ones for:\n",
    "\n",
    "- [Linear models](https://scikit-learn.org/stable/modules/linear_model.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#generalized-linear-models))\n",
    "- [Nearest neighbours](https://scikit-learn.org/stable/modules/neighbors.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#nearest-neighbors))\n",
    "- [Support vector machines](https://scikit-learn.org/stable/modules/svm.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#support-vector-machines))\n",
    "- [Decision trees](https://scikit-learn.org/stable/modules/tree.html) ([examples](https://scikit-learn.org/stable/auto_examples/index.html#decision-trees))\n",
    "- And [many more](https://scikit-learn.org/stable/index.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732b640-656f-4dff-a83a-173b4cbadc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "(tensorflow)=\n",
    "### [TensorFlow](https://www.tensorflow.org/)\n",
    "\n",
    "Tensorflow is an end-to-end open source machine learning platform.\n",
    "\n",
    "- [Documentation](https://www.tensorflow.org/guide)\n",
    "- [Tutorials](https://www.tensorflow.org/tutorials)\n",
    "- [Examples](https://keras.io/examples/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f618cc7-107a-46a5-9596-3fb9dad8b224",
   "metadata": {},
   "source": [
    "TensorFlow has a user-friendly higher-level APIs (Application Programming Interface) called [Keras](https://keras.io/).\n",
    "\n",
    "Keras includes a wide range of high-level objects ([tutorials](https://keras.io/guides/)) including:\n",
    "\n",
    "- [Models](https://keras.io/api/models/)\n",
    "- [Layers](https://keras.io/api/layers/)\n",
    "    - [Activations](https://keras.io/api/layers/activations) e.g., sigmoid\n",
    "    - [Regularisers](https://keras.io/api/layers/regularizers/) e.g., L2\n",
    "    - [Convolutional](https://keras.io/api/layers/convolution_layers/) e.g., Conv2D\n",
    "    - [Recurrent](https://keras.io/api/layers/recurrent_layers/) e.g., LSTM (long-short-term-memory)\n",
    "    - [Preprocessing](https://keras.io/api/layers/preprocessing_layers/) e.g., vectorisation\n",
    "- [Optimisers](https://keras.io/api/optimizers/) e.g., Adam\n",
    "- [Losses](https://keras.io/api/losses/) e.g., MeanSquaredError\n",
    "- [Metrics](https://keras.io/api/metrics/) e.g., Accuracy\n",
    "\n",
    "You can always go lower level when required (e.g., custom objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d870831-803d-410f-942e-8552e7900844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Through Keras and TensorFlow you create models and layers using any of the [following APIs](https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html):\n",
    "\n",
    "| | [Sequential](https://keras.io/guides/sequential_model/) | [Functional](https://keras.io/guides/functional_api/) | [Subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models/) |\n",
    "| --- | --- | --- | --- |\n",
    "| API style | Symbolic (abstract) | Symbolic | Imperative (compute as you run) |\n",
    "| Data structure | Graph: Linear stack of layers. | Graph: Non-linear DAG (directed acyclic graph) of layers (can be shared). | Object-orientated. Write the forward pass (backward pass is automatic) | \n",
    "| Shared layers and multiple inputs/outputs | No. Each layer has one input and one output. | Yes. Each layer can have multiple inputs and outputs. | Yes. |\n",
    "| Main pros/cons | Simplest, (re)usability (easily saved), model checks to catch errors early, static | Like seqential, but more flexible | Maximum flexibility, no model checks, more complex, dynamic |\n",
    "| Show model graph | Yes | Yes | Can add via the guidance [here](https://github.com/tensorflow/tensorflow/issues/31647#issuecomment-692586409). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374654f-3a27-4df6-8da7-37a5d144fde0",
   "metadata": {},
   "source": [
    "There are many [libraries and extensions](https://www.tensorflow.org/resources/libraries-extensions) including:\n",
    "\n",
    "- [TensorFlow Extended](https://www.tensorflow.org/tfx) for deployment.\n",
    "- [TensorFlow Lite](https://www.tensorflow.org/lite/guide) for mobile and IoT (internet of things) devices.\n",
    "- [TensorBoard](https://www.tensorflow.org/tensorboard) for visualising the experiment results.\n",
    "- [And many more (including projects, papers, and experiments)](https://github.com/jtoy/awesome-tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676c92f-d0a2-4e16-bc4d-ef5043525533",
   "metadata": {},
   "source": [
    "(pytorch)=\n",
    "### [PyTorch](https://pytorch.org/)\n",
    "\n",
    "PyTorch is an end-to-end open source machine learning platform.\n",
    "\n",
    "- [Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- [Tutorials](https://pytorch.org/tutorials/)\n",
    "\n",
    "PyTorch has a user-friendly higher-level API called [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/).\n",
    "\n",
    "PyTorch Lightning helps write boilerplate code, scale out to multiple devices, and other helpful things ([tutorials](https://pytorchlightning.github.io/lightning-tutorials/index.html)).\n",
    "\n",
    "You can always go lower level when required (e.g., custom objects).\n",
    "\n",
    "Similar to TensorFlow/Keras, you can create models and layers in PyTorch using either Sequential or Subclassing APIs (or in combination). These have similar features to the table above, where the Sequential API is simpler and the Subclassing API enables flexibility.\n",
    "\n",
    "There are many [libraries and extensions](https://pytorch.org/ecosystem/) including:\n",
    "\n",
    "- [TorchServe](https://pytorch.org/serve/) for deployment.\n",
    "- [Pytorch Live](https://pytorch.org/live/) for mobile and IoT devices.\n",
    "- [And many more (including projects, papers, and experiments)](https://github.com/bharathgs/Awesome-pytorch-list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f3b5c7-f520-49db-94f9-6056d8132131",
   "metadata": {},
   "source": [
    "## Example - Linear regression\n",
    "\n",
    "Let's start with a simple example fitting a straight line to data.\n",
    "\n",
    "We'll see how this in done in each of three key tools we cover here: scikit-learn, TensorFlow, and PyTorch.\n",
    "\n",
    "Let's create some (noisy) data to train on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da44fa9-d46c-40d4-9f7f-954d2364ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd737f-57a5-4387-9f24-2b8a9833e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_linear_data(num_points):\n",
    "    x = np.arange(num_points)\n",
    "    noise = np.random.normal(0, 1, num_points)\n",
    "    y = 2 * x + noise\n",
    "    # convert to 2D arrays\n",
    "    x, y = x.reshape(-1, 1), y.reshape(-1, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6009ddc-563d-4c4f-8e26-453dd2794d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_noisy_linear_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cf489-406c-4283-bba1-3daf9febaf41",
   "metadata": {},
   "source": [
    "```{caution} \n",
    "\n",
    "Input arrays to models needs to be 2 dimensional (2D) i.e., a column of rows.\n",
    "\n",
    "For example, instead of one row:\n",
    "\n",
    "`>>> np.arange(10)`  \n",
    "`array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])`  \n",
    "\n",
    "Convert this to a column of rows using `.reshape(-1, 1)`:  \n",
    "\n",
    "`>>> np.arange(10).reshape(-1, 1)`  \n",
    "`array([[0],`  \n",
    "`       [1],`  \n",
    "`       [2],`  \n",
    "`       [3],`  \n",
    "`       [4],`  \n",
    "`       [5],`  \n",
    "`       [6],`  \n",
    "`       [7],`  \n",
    "`       [8],`  \n",
    "`       [9]])`  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4da99-a120-4a3d-8b48-1c79042662f7",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "First, let's try with [scikit-learn](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3cce2-5397-4a8f-8a57-0998dd883595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d9bd8-647e-48ca-b008-9fe731bcad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb6d28-d60b-44a0-904e-d888c27ab0cb",
   "metadata": {},
   "source": [
    "When fit is called for Linear Regression, the _loss_ that is trying to be minimised is the _mean squared error_ between the predictions and the actual values.\n",
    "\n",
    "This determines what parameters the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc66adf-083e-4756-8658-2525a5da3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd999b8-57fa-4abd-b680-a65df7ecd28d",
   "metadata": {},
   "source": [
    "The data was from the line `y = 2x`, so the gradient was 2.\n",
    "\n",
    "Let's see what the model estimated it to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bc2f4-40e8-4e2e-900a-1a04b478381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ffc9d-d04e-4290-a506-82d65c82f1a2",
   "metadata": {},
   "source": [
    "Pretty close, considering there was only 10 training data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abb76f-86c2-41ca-85f9-1252c2865af9",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now, for **TensorFlow**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28b86a-b5f7-4633-8ce0-3b727a305ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c857048-a87e-4c09-be4f-1c19c42873a1",
   "metadata": {},
   "source": [
    "Create the model (using the simpler sequential API).\n",
    "\n",
    "Note, it's helpful to name the layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ae6a5-6944-42d1-bc5a-61498d15df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(1,), name=\"inputs\"),\n",
    "        tf.keras.layers.Dense(units=1, name=\"outputs\"),\n",
    "    ],\n",
    "    name=\"sequential\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0c356-2159-4d59-afce-5146f0763836",
   "metadata": {},
   "source": [
    "For reference, here's what this would have looked like using the functional and subclassing APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e927caa-51d0-4513-bc79-811e2b65743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1,), name=\"inputs\")\n",
    "outputs = tf.keras.layers.Dense(units=1, name=\"outputs\")(inputs)\n",
    "model_tf_functional = tf.keras.Model(inputs, outputs, name=\"functional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e51c78-c536-4baa-9379-c0f3153be067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)  # handles standard arguments e.g., name\n",
    "        self.outputs = tf.keras.layers.Dense(units=1, name=\"outputs\")\n",
    "\n",
    "    def call(self, inputs):  # have inputs as argument to call, rather than define\n",
    "        x = self.outputs(inputs)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_tf_subclassing = MyModel(name=\"subclassing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c425145-2112-4d46-a82a-d1f1c5706c15",
   "metadata": {},
   "source": [
    "You can now show the model summary.\n",
    "\n",
    "Note, this only shows layers (not the `Input` object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0f3c4-e904-42c0-bd66-a2ee977e7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eff5e2-f317-4592-96fa-165dd9365d20",
   "metadata": {},
   "source": [
    "You can also show the model graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e86528-b426-4dc0-aeff-656dc0f9ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_tf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e30465-c014-4d78-a9e5-05a20ead1700",
   "metadata": {},
   "source": [
    "Now, compile the model.\n",
    "\n",
    "The keyword arguments to `optimizer`, `loss`, and `metrics` can either be strings (e.g., `mean_squared_error`) or TensorFlow objects (e.g., `tf.keras.metrics.mean_squared_error`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e416f-5a3b-4d8e-87e0-63cd2dd72374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    optimizer=\"sgd\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4985a4-dcd7-45ca-816c-bbf82b154cd0",
   "metadata": {},
   "source": [
    "And, train the model.\n",
    "\n",
    "[Epochs](https://developers.google.com/machine-learning/glossary/#epoch) are how many passes over the whole training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334c6ea-749c-487a-93eb-33c41ab83360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    verbose=False,  # print out the metrics per epoch\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11842bb-ef87-4abe-9d3d-60a4c693220f",
   "metadata": {},
   "source": [
    "And, let's see what this model though the gradient was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffed94-249f-4c44-bfc3-c97da42582aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.weights[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c4194-6b5b-433d-bf3e-deaf24e00f69",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08376b6c-bedd-485b-a5cf-72b26c6d79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7958c9-060c-4649-8da1-b4310d45b2fe",
   "metadata": {},
   "source": [
    "Create the dataset and dataloaer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87a8eb-9bc1-4c0f-a409-97c0008e047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train).type(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(y_train).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee18038-8a22-4ed9-a14b-63995a2c9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TensorDataset(x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173db9b-f25d-4366-871f-77bc4a975b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba8de6-5a99-4f71-ad1b-cf73e04bca84",
   "metadata": {},
   "source": [
    "Create the model (using the simpler sequential API):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a64aea-30ae-4162-9751-36e5a57286b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = nn.Sequential(nn.Linear(in_features=1, out_features=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694ab82-2253-4d02-8cd1-edfdd3033891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727529c0-e74a-427a-9e90-04c73d45e7fd",
   "metadata": {},
   "source": [
    "For reference, here's what this would have looked like using the subclassing APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45666d13-066d-4da8-af3f-2ee373780f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):  # model definition\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.outputs = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x):  # the computations\n",
    "        logits = self.outputs(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model_torch_subclassing = NeuralNetwork()\n",
    "print(model_torch_subclassing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d596031-5141-46f6-aed6-85ba4eb149bc",
   "metadata": {},
   "source": [
    "Define the loss and optimiser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efaaffe-1bf6-47a0-948a-822a75d2b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimiser = torch.optim.SGD(model_torch.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d2f6d-d293-474a-ae19-4a078b03ea6a",
   "metadata": {},
   "source": [
    "Define a single training step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0c6a9-6a31-4220-91a6-a56a7d4b300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimiser):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        prediction = model(X)  # 1: forward step\n",
    "        loss = loss_function(prediction, y)  # 2: compute the objective function\n",
    "        optimiser.zero_grad()  # 3: clean the gradients\n",
    "        loss.backward()  # 4: accumulate the gradients\n",
    "        optimiser.step()  # 5: step in opposite direction of gradient (descend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4c6a2-2e68-42fb-939f-a9024dc62d6e",
   "metadata": {},
   "source": [
    "Run the training step over multiple epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d03e0-c3f2-4d2e-860d-aabbc6716c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(dataloader_train, model_torch, loss_function, optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49bcd93-06ad-4fad-ba22-0d816fb2a1bc",
   "metadata": {},
   "source": [
    "And, let's see what this model though the gradient was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2445b6-5f5f-46b7-a077-c059f2c441fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check parameter names\n",
    "for name, parameter in model_torch.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9250210-374b-4f94-bc80-b52998cc2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f8d7a-f9eb-49f3-9bf0-dd33ba6d497c",
   "metadata": {},
   "source": [
    "Now, we can see how well these models fit a line to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cca24-c4b4-4c40-8e67-328984c085b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = model_sklearn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97e974-9aee-459e-9a02-4e4f6decc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tf = model_tf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726a821-55e7-4b43-9b6d-0ce3a3655c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_torch = model_torch(x_train_tensor).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c466f2e-0499-432d-8261-a0387a73cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e07cf1-ce8c-43b2-b4f4-a8dbe1ec671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"data\": \"#1b9e77\", \"sklearn\": \"#d95f02\", \"tf\": \"#7570b3\", \"torch\": \"#66a61e\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15932110-88da-48f8-af59-27ba8cbcdfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(ax, y_pred, label, title):\n",
    "    ax.scatter(x_train, y_train, color=colors[\"data\"])\n",
    "    ax.plot(x_train, y_pred, color=colors[label], linewidth=3)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim([0, 18])\n",
    "    ax.set_xlim([0, 9])\n",
    "    ax.set_facecolor(\"whitesmoke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8abb6f-f132-4fdd-b4bb-f02884afdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(12, 4))\n",
    "ax1, ax2, ax3 = fig.subplots(1, 3)\n",
    "\n",
    "make_plot(ax1, y_pred_sklearn, \"sklearn\", \"scikit-learn\")\n",
    "make_plot(ax2, y_pred_tf, \"tf\", \"TensorFlow\")\n",
    "make_plot(ax3, y_pred_torch, \"torch\", \"PyTorch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a49675-0fe2-4865-bcc0-0dff3e3ff65e",
   "metadata": {},
   "source": [
    "They all did a good job of fitting a function to the data.\n",
    "\n",
    "In other words, they found the association in the data.\n",
    "\n",
    "However, this was a very simple example that probably didn't require machine learning (let alone deep learning).\n",
    "\n",
    "Though it demonstrates what they do.\n",
    "\n",
    "Now, let's look at something a little more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b64ae5-3e08-46e1-b00d-634a0f81fab8",
   "metadata": {},
   "source": [
    "## Example - Digit classification\n",
    "\n",
    "Let's train a model to recognise digits using the classic [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "This is a classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f12ea-a578-43ec-9b00-9960b48a5918",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "First, with [scikit-learn](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504041c-e6f1-4555-8a70-4397f224ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c3bab-6c75-4da1-913d-9b92d8c4f780",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f933f0-c80d-4e3f-9a38-6cb08aa1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651945d-76aa-4344-943a-aa969d334f71",
   "metadata": {},
   "source": [
    "Take a look at the labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a005238-5e98-402c-9590-03ce0e28be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d83c6-6527-4eca-b7fc-23e34aa97293",
   "metadata": {},
   "source": [
    "#### Preprocess and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba99d9-5ea0-489f-86e6-e7d1c8d9db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(digits):\n",
    "    # the data comes as 2D 8x8 pixels\n",
    "    # flatten the images to 1D 64 pixels\n",
    "    n_samples = len(digits.images)\n",
    "    data = digits.images.reshape((n_samples, -1))\n",
    "    return n_samples, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e28ca8-5e7f-4633-bb70-9a88bc6e33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, data = preprocess_data(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aea168-cc0c-4729-8c19-7374a3a5d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd6e41-d69d-4b57-baf5-fb2c4978de78",
   "metadata": {},
   "source": [
    "#### Create a model\n",
    "\n",
    "Here, we will use a [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) (a type of support vector machine).\n",
    "\n",
    "This model focuses on the two hardest to classify examples and places support vectors between them to form the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed26cc-1768-4392-8438-8d10cb4aa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce02572-5b4b-4d24-bd06-e592f4b608b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2234a-bfd9-42af-8ed5-430b7149df0f",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025a658-a6fa-4619-a7c0-1be95d468968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff8a3f-d7f7-4d52-b5b8-19f655df8a24",
   "metadata": {},
   "source": [
    "#### Use the model to predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7866281-7779-4b92-bf03-ca65647a62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb390b74-03d8-4569-876b-e19886d3bd79",
   "metadata": {},
   "source": [
    "Take a look at the predictions for these test digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dc823-dff0-4d8c-b23b-4415438eb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)  # 1D 64 pixels to 2D 8*8 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a01b1a-401e-4e7a-9590-3165cd5ad85f",
   "metadata": {},
   "source": [
    "#### How well did our model do overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c9975-5085-423c-9705-cc30db06fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789c732-9197-42b1-a5a0-1b144b8e51af",
   "metadata": {},
   "source": [
    "97% accuracy is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fab801-a015-4a6a-8b18-2c6e2d57c138",
   "metadata": {},
   "source": [
    "Let's do some quick error analysis using a [confusion matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).\n",
    "\n",
    "This shows how well the classification model did for each category.\n",
    "\n",
    "The predictions are on the x-axis and the true labels from the test data are on the y-axis.\n",
    "\n",
    "A perfect score would be where the predictions always match the true labels (i.e., all values are on the diagonal line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39735d-09c6-4f19-a0df-93673a8a6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "confusion_matrix.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bd0ae-5631-4a3e-9531-116f8f2c4190",
   "metadata": {},
   "source": [
    "We can see that the although the model did well, it struggled with 3's by confusing them with 5's, 7's, and 8's.\n",
    "\n",
    "This points us in the direction of how we might improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7be2e0-c543-4f94-a9ef-8bad75d972db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400193db-2523-4878-8944-53d2810c3214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7fc53b-e1a4-4f8e-8412-716ae8908485",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f79f22-a60e-4aa9-83b9-5534ec69020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa733f-e4f6-44fe-aa7d-8bf32fe2b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7dd2dc-9051-4e2c-8035-3db8e7498767",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = cross_val_score(model, X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9350fd-e46b-461d-b61b-f3a32a0d0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b8d0b-0cd1-4846-ac3c-e6635f035fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CV accuracy = {test_scores.mean():0.2f} (+/- {test_scores.std():0.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e32e-a49f-4ac4-9fe0-1a2ef4fd4e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e4df9c-bf68-41cf-a34f-a7e95b615de8",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f64c2-e95e-4175-92a8-27e934e8cf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bc8175-beed-44b3-9b96-cb8743f87fb3",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now, with [TensorFlow](https://www.tensorflow.org/datasets/keras_example).\n",
    "\n",
    "First, set the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463831d1-df89-4575-8a25-4aa5d98e4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75afe544-9b97-44cc-9037-72f0b1cfc3a6",
   "metadata": {},
   "source": [
    "Check whether there are any [GPUs (Graphical Processing Units)](https://www.tensorflow.org/guide/gpu) available.\n",
    "\n",
    "Note, the [device](https://developers.google.com/machine-learning/glossary/#device) is the hardware that TensorFlow runs on (e.g., CPUs (Central Processing Units), GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3b3cc-0d98-4f54-bf8e-b6bfed74c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244e268-847e-462b-9215-c39d1f967e8e",
   "metadata": {},
   "source": [
    "#### Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3086bf5-2d57-4039-835e-a69e6d1ddd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab06ce2-cba5-4ba8-9cdb-1a11565bd43c",
   "metadata": {},
   "source": [
    "Take a look at some of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e6699-8438-42eb-b487-ef803ea6ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, train_images, train_labels):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(28, 28)  # 1D 784 pixels to 2D 28*28 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4240e6-e735-40c3-acde-b9243ce84e16",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "\n",
    "Can use any of the sequential, functional, or subclassing APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dca4fd-c2e6-497c-89f2-583c040b16d6",
   "metadata": {},
   "source": [
    "Let's use the simpler [Sequential API](https://keras.io/guides/sequential_model/) for now.\n",
    "\n",
    "You could also use many `.add()` calls instead of the list.\n",
    "\n",
    "```{note}\n",
    "You could make the final layer a softmax (to output probabilities directly), though this is [discouraged](https://www.tensorflow.org/tutorials/quickstart/beginner#build_a_machine_learning_model) for numerical stability reasons.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c818f37-fbe6-4077-84d1-87bb9b706942",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "It's often useful to place pre-processing steps into the model pipeline too.\n",
    "\n",
    "For example, here we flatten the 2D image to a 1D tensor and [normalise](https://developers.google.com/machine-learning/glossary/#normalization) the images to greyscale (i.e., convert the values to between -1 and 1 or 0 and 1).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f011921-a2e8-4e55-9d23-43bb545ab5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(28, 28), name=\"inputs\"),\n",
    "        tf.keras.layers.Flatten(name=\"flatten\"),\n",
    "        tf.keras.layers.Rescaling(1.0 / 255, name=\"normalise\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.Dense(10, name=\"outputs\"),  # 1 unit per class\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f97456-7cc1-498b-ae48-df93616be68a",
   "metadata": {},
   "source": [
    "We can now also visualise the architecure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92fbd72-88c1-4cad-858a-ef72c619ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16066285-560f-4a97-81fe-8fc406763b6f",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "It's useful to name the metrics, especially if there's more than one.\n",
    "\n",
    "Here, we'll use the Adam optimiser.\n",
    "\n",
    "SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bbe3c-a8e9-41cb-a31b-64612c51fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ),  # ensure classifies using logits\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c0668-dd78-4d12-aae1-0c213a118868",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data\n",
    "\n",
    "The `fit()` call returns a `history` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28df11-dcfd-4c2f-85ba-a4daa5f1b79e",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The `validation_split` keyword argument can only be used for NumPy training data.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e07edd-d5b0-4521-bafc-4abbc734ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=2,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=False,  # print the output from each epoch\n",
    "    validation_split=0.2,  # automatically set apart a validation set: 0.2 means 20% for validation\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d6d64-e533-490a-a339-3d862a305dff",
   "metadata": {},
   "source": [
    "The `history.history` dictionary then contains the loss and metrics per epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a428cb-702d-45aa-b3d6-f3d9d864a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31481e-bb0e-477f-9dc7-9a166a9e203d",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "\n",
    "Use the model for predictions with [`model.predict()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) (i.e., inference).\n",
    "\n",
    "Models return [logits or log-odds](logits_and_log_odds) (we'll cover these in the next lesson). If you'd like these be to probabilities, add a softmax layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00efbac-8860-4dae-9107-67b92122f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2506b73-053f-4105-acbb-686481e7270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdb0fd-b334-4aab-be2d-624d33b03c5d",
   "metadata": {},
   "source": [
    "Each prediction has a probability per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c14844-e7ca-4cb6-92f4-b7f128a4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367c9f2-0e38-4a5c-9593-dff8a03be740",
   "metadata": {},
   "source": [
    "The most likely category can be found by finding the maximum of these (using [`np.argmax`](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c959-777c-4782-a0f5-498e41db74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b45b84-3882-431c-bcfb-9c0f4ded9742",
   "metadata": {},
   "source": [
    "So, the model things the first digit is a 7.\n",
    "\n",
    "Let's plot the first four test digits with their predictions to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df94d9-7b07-43ea-b458-6b6bae27bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, test_images, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    image = tf.reshape(image, (28, 28))  # 1D 784 pixels to 2D 28*28 pixels for plotting\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {np.argmax(prediction):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902a6c3-b4e2-4007-beae-c05bb3c7c246",
   "metadata": {},
   "source": [
    "#### Let's now evaluate the model overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d338cb-f408-4d84-bdc8-471aa6d006b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy (R2): {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64b48a-92ed-41ac-8191-24986b0eb0b5",
   "metadata": {},
   "source": [
    "Similar to scikit-learn an overall test accuracy of 97% is good (especially for this simple example).\n",
    "\n",
    "Note, that the training accuracy and validation accuracy were both 97% too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e71b3-13a5-44c4-8e20-7cb023826263",
   "metadata": {},
   "source": [
    "A before, let's have a look at a confusion matrix for this.\n",
    "\n",
    "_TensorFlow does have its own [`confusion_matrix`](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix) method. Though I'll use the scikit-learn one here again as it has a nice plot feature._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59296f-6c03-41e2-b2df-fdb228ec677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    test_labels, np.argmax(y_pred, axis=1)\n",
    ")\n",
    "confusion_matrix.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373598e-833b-4367-915d-200b3f19f68f",
   "metadata": {},
   "source": [
    "This model did well for most digits, though struggled a bit with 5's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987aadde-3f0f-48b1-bccf-029d85118673",
   "metadata": {},
   "source": [
    "#### [Save the model](https://www.tensorflow.org/tutorials/keras/save_and_load)\n",
    "\n",
    "A model includes:\n",
    "\n",
    "- Architecture\n",
    "- Weights (i.e., state)\n",
    "- Configuration (e.g., optimiser, loss, metrics)\n",
    "\n",
    "Can save the whole or parts.\n",
    "\n",
    "Formats:\n",
    "\n",
    "- [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model): single archive (recommended)\n",
    "    - Save: `model.save()` or `tf.keras.models.save_model()`\n",
    "    - Load: `tf.keras.models.load_model()`\n",
    "    - Keras H5 was the older format\n",
    "- Architecture only (JSON)\n",
    "    - Save: `get_config()` and `tf.keras.models.model_to_json()`\n",
    "    - Load: `from_config()` and `tf.keras.models.model_from_json()`\n",
    "- Weights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68540d-7fec-4ac0-a6fe-f8c9464116e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_models = f\"{os.getcwd()}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8bb69-bc13-45ff-86ac-aa5b04dd38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{path_models}/model_tf_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3a91-42a2-43d7-9445-7cd1687ba4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path_models}/model_tf_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5a400-8551-42ab-be98-ac77f1d3ec48",
   "metadata": {},
   "source": [
    "#### Load the model\n",
    "\n",
    "Reload the saved model and evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72cb63-551f-4b31-86d3-7dafade79431",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(f\"{path_models}/model_tf_mnist\")\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450d3fd-5c7f-4145-bc5c-e7ed092c4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6fe0c-9c1f-4855-aca9-95473d916e6b",
   "metadata": {},
   "source": [
    "### [PyTorch](https://colab.research.google.com/github/PyTorchLightning/lightning-tutorials/blob/publication/.notebooks/lightning_examples/mnist-hello-world.ipynb)\n",
    "\n",
    "Here, we'll do a [simple example](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=nbQAcRna5e_q) using PyTorch Lightning.\n",
    "\n",
    "This will just include training (i.e., no validation or testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b733458f-4d06-43fa-9d34-2eb07b4b2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e30ee2-c6b7-42cd-870c-e04aa4653b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc0d0087e30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a379b5-4fe0-4184-b22c-36f61aafd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "PATH_DATASETS = f\"{os.getcwd()}/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e2ac7-a793-4394-bb87-a482ba643250",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0dc48ec-eedb-450b-94d3-bfefded7f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    MNIST(PATH_DATASETS, train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973e0fe-935a-4ebe-ae83-5b6571f71bca",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "\n",
    "This include the loss, optimiser, and training steps.\n",
    "\n",
    "`pl.LightningModule` is a `nn.Module` with more features.\n",
    "\n",
    "For more information on how to convert a PyTorch model to a PyTorch Lightning model see:\n",
    "\n",
    "- [PyTorch Lightning MasterClass](https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2) videos.\n",
    "- [Tutorial](https://pytorch-lightning.readthedocs.io/en/stable/starter/converting.html)\n",
    "- [Demonstration video](https://youtu.be/QHww1JH7IDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581aee28-980b-496d-92b8-34b8fbabdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features=28 * 28, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten inputs\n",
    "        x = self.layer1(x)  # pass inputs through hidden layer\n",
    "        output = torch.relu(x)  # run activation function for layer\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f647c2e4-009f-4751-9889-93d3b1559321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist_model = MNISTModel()\n",
    "print(mnist_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2645df9-be3b-49d7-9d11-a75701e4ced4",
   "metadata": {},
   "source": [
    "#### Create the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b445d-321e-4c6d-a829-2e8e38dff895",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "The progress bar can be too fast for Colab / Kaggle. If developing in these platforms, be sure to slow the refresh rate by increasing the value in: `callbacks=TQDMProgressBar(refresh_rate=20)`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c7cf88-f553-4980-906f-40f4925f702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=0, callbacks=TQDMProgressBar(refresh_rate=20), max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f232e-9a43-4d44-8446-5df3d7c865ce",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "910d1948-c9c5-4933-9105-3227daee329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.fit(mnist_model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832d5d9-ebab-4165-8109-e1fe3a41f4e9",
   "metadata": {},
   "source": [
    "#### (Optional) [Adding](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=gjo55nA549pU) in validation and testing to the model creation\n",
    "\n",
    "Note, `train_dataloader` is now incorporated into the model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43a6ac6c-1b2c-4cd9-8849-cfd2394eafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_features=28 * 28, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten x\n",
    "        x = self.layer1(x)  # pass inputs through hidden layer\n",
    "        output = torch.relu(x)  # run activation function for layer\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)  # predicted y output\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):  # hook for validation\n",
    "        average_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": average_val_loss}\n",
    "        return {\"val_loss\": average_val_loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        test_loss = F.cross_entropy(y_hat, y)\n",
    "        return {\"test_loss\": test_loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):  # hook for test\n",
    "        average_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        logs = {\"test_loss\": average_test_loss}\n",
    "        return {\"test_loss\": average_test_loss, \"log\": logs, \"progress_bar\": logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MNIST(\n",
    "                PATH_DATASETS,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MNIST(\n",
    "                PATH_DATASETS,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MNIST(\n",
    "                PATH_DATASETS,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=transforms.ToTensor(),\n",
    "            ),\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fcff246-ad0e-449c-b8d2-7d95767c1255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist_model = MNISTModel()\n",
    "print(mnist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c963c83f-814e-483c-9714-f9b1b93e7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=0, callbacks=TQDMProgressBar(refresh_rate=20), max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b0be4-160f-4cd9-8ab6-b582c8277d8d",
   "metadata": {},
   "source": [
    "Note, the trainer only required the model as input, as the `train_dataloader` is part of the model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc677041-07c3-412a-b1ec-7c3a547384ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.fit(mnist_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ab419-2b8c-4a68-adc5-23e737c74dcb",
   "metadata": {},
   "source": [
    "Now, testing the model is simply done by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6c0ee3b-6924-4f94-830e-6da615226e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.test(mnist_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78f2d3-d930-4462-95e2-53bda001d1a2",
   "metadata": {},
   "source": [
    "#### Save the model's internal state\n",
    "\n",
    "Saved automatically to `lightning_logs/`.\n",
    "\n",
    "Incrementally split over versions e.g., `version_0`.\n",
    "\n",
    "This then saves checkpoints per epoch, overwriting with the latest epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7888ee-64e8-40f9-9501-74a76a09a64f",
   "metadata": {},
   "source": [
    "#### [Load the model](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html#checkpointing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "314220e9-d19b-4653-8606-0c89a6eb0fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/earlacoa/repos/swd8_intro_ml/docs/lightning_logs/version_0/checkpoints/epoch=4-step=9375.ckpt\n"
     ]
    }
   ],
   "source": [
    "path_checkpoints = f\"{os.getcwd()}/lightning_logs/version_0/checkpoints\"\n",
    "path_model = f\"{path_checkpoints}/{os.listdir(path_checkpoints)[0]}\"\n",
    "print(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d549d74-b305-4bc2-a623-28fa89014793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = MNISTModel.load_from_checkpoint(path_model)\n",
    "print(reloaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <tools>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970bc04-88fc-4cf2-89b3-7b4cdc8bc1f8",
   "metadata": {},
   "source": [
    "## Further information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b8126-a770-470e-af61-023eea1593fa",
   "metadata": {},
   "source": [
    "### Good practices\n",
    "\n",
    "- Many decisions around model architecture are based on previous work, literature, and trial-and-error.\n",
    "- Debugging: \n",
    "    - Test each part individually, before testing the whole.\n",
    "    - Check the model summary and visualise the architecture.\n",
    "    - Use debug modes:\n",
    "        - Add `run_eagerly=True` with the call to `fit()` in Keras.\n",
    "        - Use `Trainer(fast_dev_run=True)` in PyTorch Lightning.\n",
    "    - Tips for [Keras](https://keras.io/examples/keras_recipes/debugging_tips/) and [PyTorch Lightning](https://youtu.be/BoiqJSAgPsQ).\n",
    "- Offloading computations to a GPU may not be beneficial for small models.\n",
    "- Tips for optimising GPU performance from [TensorFlow](https://www.tensorflow.org/guide/gpu_performance_analysis), [NVIDIA](https://docs.nvidia.com/deeplearning/performance/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Other options\n",
    "\n",
    "There are [many other options](https://github.com/josephmisiti/awesome-machine-learning), including:\n",
    "\n",
    "- [JAX](https://jax.readthedocs.io/en/latest/#)\n",
    "    - A library for GPU accelerated NumPy with automatic differentiation.\n",
    "- [Flax](https://github.com/google/flax)\n",
    "    - A neural network library and ecosystem for JAX that is designed for flexibility.\n",
    "- [Haiku](https://dm-haiku.readthedocs.io/en/latest/)\n",
    "    - Built on top of JAX to provide simple, composable abstractions for machine learning research.\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/stable/)\n",
    "    - Gradient boosting library.\n",
    "- [Caffe](https://caffe.berkeleyvision.org/)\n",
    "    - Deep learning framework.\n",
    "- [Sonnet](https://sonnet.readthedocs.io/en/latest/)\n",
    "    - High-level API for TensorFlow.\n",
    "- [fastai](https://docs.fast.ai/)\n",
    "    - High-level API for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c5a0f-2f82-441c-9097-32417fff0152",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)\n",
    "- [Project template for PyTorch Lightning](https://github.com/PyTorchLightning/deep-learning-project-template)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "swd8_intro_ml",
   "language": "python",
   "name": "swd8_intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
