{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/03_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795cc13-b561-4d40-9fbf-d368b23ba24f",
   "metadata": {},
   "source": [
    "```{note}\n",
    "If youâ€™re in COLAB or have a local CUDA GPU, you can follow along with the more computationally intensive training in this lesson.\n",
    "\n",
    "For those in COLAB, ensure the session is using a GPU by going to: Runtime > Change runtime type > Hardware accelerator = GPU.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4991e-9de8-4418-8c5c-6d904fb9b4de",
   "metadata": {},
   "source": [
    "## [Tensors](tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5936a38-7bef-47b0-b6b6-c759fa16623f",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a410a24-8ba8-4989-8abf-2d501504e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996f49d-5272-4d32-bc4f-c52c7fe9f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(size=(1,))  # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79c904-7c31-463b-887d-dc950570c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(size=(3,))  # vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4198ea-0bb7-4e3a-9446-c7b5b0e4c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(size=(3, 3))  # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092f4db-f0df-487d-a8ce-60bfbfacab8b",
   "metadata": {},
   "source": [
    "### [TensorFlow](https://www.tensorflow.org/guide/tensor)\n",
    "\n",
    "Tensors are immutable.\n",
    "\n",
    "Also have [sparse tensors](https://www.tensorflow.org/guide/tensor#sparse_tensors) (mostly zeros), and a range of other data structures such as [variables](https://www.tensorflow.org/guide/variable).\n",
    "\n",
    "Can do [maths](https://www.tensorflow.org/api_docs/python/tf/math) with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a19ca9-dea7-4599-a67d-76bd46a41974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7b10b-b41c-46a0-981a-613cb23c6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.normal(shape=(1,))  # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b87f7b-eb97-4738-a6f9-fe76997c5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.normal(shape=(3,))  # vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736dd9d5-6791-42c7-8d1f-067de73be98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.normal(shape=(3, 3))  # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d28ce-8033-41e6-a8b9-8f99a3e075a6",
   "metadata": {},
   "source": [
    "### [PyTorch](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "Can do [maths](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html#math-logic-with-pytorch-tensors) with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dcb846-3bbf-41a9-bd0a-09b191d188fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114a83b-b122-4616-9c10-c41759d90a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(size=(1,))  # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef512f-463c-4a6b-bc09-e9fc9025402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(size=(3,))  # vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ce9e8-ef8d-4026-8014-bdcf3ed3802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(size=(3, 3))  # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da975b7-c7f9-4b36-b83f-9f16330d4686",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "Use random seeds to assist reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a9e2a-3050-4cfe-8092-0096b91aff37",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48155a5-abcb-4ea8-90f0-1ea70238e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab3bbc-9c60-4c0b-81ab-82eb05d53611",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "Used by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c36990-04bf-4370-9e33-e1951e2fab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39779c78-2092-44d5-a05f-8a14a2942b98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [scikit-learn](https://scikit-learn.org/stable/common_pitfalls.html#controlling-randomness)\n",
    "\n",
    "Any object that uses the `random_state` keyword, set it to `rng` rather than `None`.\n",
    "\n",
    "For example, `random_state` is used in:\n",
    "\n",
    "- `sklearn.model_selection.train_test_split`\n",
    "- `sklearn.datasets.make_classification`\n",
    "- `sklearn.model_selection.KFold`\n",
    "- `sklearn.ensemble.RandomForestClassifier`\n",
    "\n",
    "```python\n",
    "rng = np.random.RandomState(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dce257-38a3-4989-9efd-3b9f736803a0",
   "metadata": {},
   "source": [
    "### TensorFlow (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1365d-d259-4739-b0d7-469236ba90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6040-25b5-4ec0-988e-63050855516c",
   "metadata": {},
   "source": [
    "### [PyTorch (Lightning)](https://pytorch.org/docs/stable/notes/randomness.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcdadd-0595-4e29-8c84-483d31350469",
   "metadata": {},
   "source": [
    "For PyTorch, there are separate seeds for the CPU and GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04d9a5-f228-4f41-9861-f5cd9283d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # cpu\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # gpu\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6f564-76bf-442c-84b7-39e5706e2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf2d63-2694-4fa5-a32b-61994e46c873",
   "metadata": {},
   "source": [
    "PyTorch Lightning also has its own seed function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdca240-3554-43b2-a333-806f422e77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843b5a8-d141-4901-b67b-31d1b78c1c62",
   "metadata": {},
   "source": [
    "Additionaly, some operations on GPUs are implemented stochastically for efficiency.\n",
    "\n",
    "To make your GPU workflow deterministic, you may also need to set:\n",
    "\n",
    "```python\n",
    "# in pytorch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# in pytorch lightning trainer\n",
    "Trainer(deterministic=True)\n",
    "\n",
    "# in the pytorch lightning dataloader\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)\n",
    "\n",
    "DataLoader(\n",
    "    train_dataset,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=generator,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65f1a5-a51d-4c98-adc2-6376ed7b92e6",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "It's good practice to try and reproduce your own work, to check that this is working correctly.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c1da7-4b22-40d6-95ef-2f6a2a628dfd",
   "metadata": {},
   "source": [
    "## Data pipelines\n",
    "\n",
    "The data pipeline can be useful:\n",
    "\n",
    "- When the data does not fit in memory.\n",
    "- When the data requires pre-processing.\n",
    "- To efficiently use hardware.\n",
    "\n",
    "The steps can include:\n",
    "\n",
    "- Extract e.g., read data from memory / storage.\n",
    "- Transform e.g., pre-processing, batching, shuffling.\n",
    "- Load e.g., transfer to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f9d7d-7a52-42a1-ace9-b235cc7d97d1",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9f5dc-8244-493d-bf5e-e3eb0b9ede0d",
   "metadata": {},
   "source": [
    "#### scikit-learn\n",
    "\n",
    "##### [Datasets](https://scikit-learn.org/stable/datasets.html)\n",
    "\n",
    "`sklearn.datasets` has a range of [toy](https://scikit-learn.org/stable/datasets/toy_dataset.html) and [real-world](https://scikit-learn.org/stable/datasets/real_world.html) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea457a9-411d-45b3-8ac3-d9fc5420c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d24aa0-0448-4bc8-98f9-ddb25165f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399ba2d-06f4-4735-be3a-c6eda1ef47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a9ee7-8cdd-48e7-8d2a-42135a378746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california_housing = datasets.fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd185b7-8465-4bea-b760-f1ebe7c39d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california_housing[\"frame\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011c44d-e812-4246-8af2-3c6a38301e36",
   "metadata": {},
   "source": [
    "##### [Pipelines](https://scikit-learn.org/stable/modules/compose.html)\n",
    "\n",
    "Create a pipeline of multiple pre-processing steps or estimators.\n",
    "\n",
    "This is useful for many reasons such as convenience, reproduciblity, and avoiding data leakage.\n",
    "\n",
    "You can create data pipelines via a list of key-value pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c62a1-1785-4ae1-adbf-f93c9618ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d3deb-1275-4b18-b1d8-8b53bb4ec88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347497d3-61ee-408e-a0a4-af8ece00433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"reduce_dim\", PCA()), (\"clf\", SVC())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995d627-261d-44af-864f-cb0e31822b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee9d72-5dc4-43bf-a08b-26dcacaaa0ee",
   "metadata": {},
   "source": [
    "Or, you by using the `make_pipeline` function and passing in classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7fa3c-0781-440a-934a-78d31dc3fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a634a-8982-4526-9fc7-62ce44cb1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71374702-71dd-4c8b-8210-3d7464df949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_pipeline(Binarizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc9f84-c149-4142-b6d4-68616b19f312",
   "metadata": {},
   "source": [
    "#### TensorFlow (Keras)\n",
    "\n",
    "[Keras](https://keras.io/api/data_loading/) models accept three types of inputs:\n",
    "\n",
    "- [NumPy arrays](https://www.tensorflow.org/guide/data#consuming_numpy_arrays)\n",
    "    - Suitable for when the data fits in memory.\n",
    "- [TensorFlow Dataset objects](https://www.tensorflow.org/guide/data#dataset_structure)\n",
    "    - Suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n",
    "- [Python generators](https://www.tensorflow.org/guide/data#consuming_python_generators)\n",
    "    - Suitable for custom processing yielding batches of data (subclasses of `tf.keras.utils.Sequence` class).\n",
    "\n",
    "The documentation has more information on different data formats, such as [CSV](https://www.tensorflow.org/tutorials/load_data/csv) and [Pandas DataFrames](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe).\n",
    "\n",
    "Keras features a range of utilities to help you turn raw data on disk into a Dataset:\n",
    "\n",
    "- [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) turns image files sorted into class-specific folders into a labeled dataset of image tensors.\n",
    "- [`tf.keras.utils.text_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory) does the same for text files.\n",
    "- [`tf.keras.utils.timeseries_dataset_from_array`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array) creates a dataset of sliding windows over a timeseries provided as array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db49d45-ad5f-4e28-9889-26d9b2a2ecc8",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "If you have a large dataset and you are training on GPU(s), consider using `Dataset` objects, since they will take care of performance-critical details, such as:\n",
    "\n",
    "- Asynchronously preprocessing your data on CPU while your GPU is busy, and buffering it into a queue.\n",
    "- Prefetching data on GPU memory so it's immediately available when the GPU has finished processing the previous batch, so you can reach full GPU utilization.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db523169-4942-4041-a131-eaa2e07c0554",
   "metadata": {},
   "source": [
    "##### [Keras Utilities](https://www.tensorflow.org/tutorials/load_data/images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48778cb2-edee-4560-9873-45056562cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d3c23-1049-419a-a928-314ba5bf62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "    data_dir = tf.keras.utils.get_file(\n",
    "        origin=dataset_url, fname=\"flower_photos\", untar=True\n",
    "    )\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    IMAGE_HEIGHT = 180\n",
    "    IMAGE_WIDTH = 180\n",
    "\n",
    "    ds_train = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de68954-8fdc-4cde-b0b1-a40efe15af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf055e9-a7fb-4a31-a9ea-5ad14874be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ds_train.class_names\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in ds_train.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0a444-97e3-45ff-97f8-ca86280d1ff7",
   "metadata": {},
   "source": [
    "##### [TensorFlow Datasets](https://www.tensorflow.org/datasets/overview)\n",
    "\n",
    "Can [split](https://www.tensorflow.org/datasets/splits) the data on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63998e23-0668-496c-9651-96cd4f94f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dc020-6c06-4712-a635-f9f9d2352787",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    (ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "        \"tf_flowers\",\n",
    "        split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "        with_info=True,  # returns (img, label) instead of {image': img, 'label': label}\n",
    "        as_supervised=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5d208-76f4-4b06-9ac0-c87aa5908ec0",
   "metadata": {},
   "source": [
    "##### [NumPy to TensorFlow Dataset](https://www.tensorflow.org/tutorials/load_data/numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663c5cd-afb7-44d7-b4ff-3a53bd7c0d03",
   "metadata": {},
   "source": [
    "Load a `.npz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a39e2-ad27-4fdc-a5f6-8b65c0f62aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\"\n",
    "\n",
    "path = tf.keras.utils.get_file(\"mnist.npz\", DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data[\"x_train\"]\n",
    "    y_train = data[\"y_train\"]\n",
    "    x_test = data[\"x_test\"]\n",
    "    y_test = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac4fc1-09b1-4e51-958a-0603248bb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84dde0-0dd0-480b-8e62-2cf94cb9ec98",
   "metadata": {},
   "source": [
    "Convert to a TensorFlow object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6ccfa-02d1-42d3-b4fc-3a32f78254a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a1720-77d5-4d44-973b-60dd2c2a1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14097824-23f1-425b-bfa5-bbb6c077e1e2",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch-lightning.readthedocs.io/en/stable/guides/data.html)\n",
    "\n",
    "There are few different options for data:\n",
    "\n",
    "- [Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#loading-a-dataset)\n",
    "    - Maps keys to data samples.\n",
    "    - Also, [Iterable Datasets](https://pytorch-lightning.readthedocs.io/en/stable/guides/data.html#iterable-datasets) for sequential data.\n",
    "- [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders)\n",
    "    - Wraps an iterable around Dataset.\n",
    "- [LightningDataModule](https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#datamodules)\n",
    "    - A collection of training/validation/test/predict DataLoaders, along with their preprocessing/downloading steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dbc59-f5c1-4acc-a4a3-a96a5c64b7cc",
   "metadata": {},
   "source": [
    "##### [Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#loading-a-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469271c5-ef63-41aa-9b35-4259cb35d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383699f7-90d8-4218-90fa-e156336d788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = f\"{os.getcwd()}/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69069f-e058-4938-94f4-59e8607f3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(data_path, train=True, download=True)\n",
    "test_dataset = MNIST(data_path, train=False, download=True)\n",
    "predict_dataset = MNIST(data_path, train=False, download=True)\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [55000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f057083-b9f1-4813-91de-88da2c413e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf7198-e0f7-4dbe-85c7-5962d7c2903f",
   "metadata": {},
   "source": [
    "##### [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf26463-14a5-43a7-874b-2bddd782441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95363e3-5638-4f66-a867-2bc297e98839",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "predict_dataloader = DataLoader(predict_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a72e01-6f9b-47a0-8d5e-dc53386862db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea32850-3391-4be3-a36b-8ca70cb28196",
   "metadata": {},
   "source": [
    "##### [LightningDataModule](https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#datamodules)\n",
    "\n",
    "Decouples the data hooks from the PyTorch Lightning model, so you can develop dataset agnostic models with reusable and sharable DataModules.\n",
    "\n",
    "For multi-node training, can add [`prepare_data_per_node`](https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#prepare-data-per-node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57c3b8-59b3-45f9-bdad-cd6ab6882598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094b861-5782-4340-b993-d1ee29f48b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path=data_path, batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),  # specific to MNIST\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data once, useful for distributed training to avoid duplicates\n",
    "        MNIST(self.data_path, train=True, download=True)\n",
    "        MNIST(self.data_path, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_path, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(\n",
    "                self.data_path, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "        if stage == \"predict\" or stage is None:\n",
    "            self.mnist_predict = MNIST(\n",
    "                self.data_path, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf8228-c538-4a94-a328-eb2c111bf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MNISTDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24251d46-e087-4b35-a909-8c51df776753",
   "metadata": {},
   "source": [
    "You can then [use the LightningDataModule in the Trainer](https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#using-a-datamodule):\n",
    "\n",
    "```python\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "trainer.test(datamodule=datamodule)\n",
    "```\n",
    "\n",
    "Now you can also swap out the datamodule for another one:\n",
    "\n",
    "```python\n",
    "datamodule = FashionMNISTDataModule()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2f4e8-6cf8-4289-a76d-0f56f1145e27",
   "metadata": {},
   "source": [
    "### Shuffle\n",
    "\n",
    "Shuffle the _training_ data to help with training accuracy.\n",
    "\n",
    "Normally, the _test_ data is not shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c93f5c-bb08-44b4-805c-14f3e5aa05ea",
   "metadata": {},
   "source": [
    "#### TensorFlow (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cab33-0c1f-4c82-a63f-4be41b09682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.shuffle(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb216e-67a5-46b7-8cd5-585b16b41995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a718df-4a61-42fd-8e18-d272e9150505",
   "metadata": {},
   "source": [
    "#### PyTorch (Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcff296-b65d-42c0-82e6-7ac21c0ef455",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a71b3-3539-49df-aebf-e45a0565af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643aa15-7bb3-4885-9889-f218ea1ae56b",
   "metadata": {
    "tags": []
   },
   "source": [
    "(batch_tf)=\n",
    "### Batch\n",
    "\n",
    "A batch is a set of examples used in one iteration of model training.\n",
    "\n",
    "The batch size is the number of examples in a batch.\n",
    "\n",
    "The optimum batch size depends on the problem and what you're optimising for. In general:\n",
    "\n",
    "- Larger batch sizes can be more performant (e.g., 128 or 256, used for distributed training).\n",
    "- Batch sizes that match the number of classes for multi-class classiciation can be more accurate (e.g., 10 for MNIST). \n",
    "- They are often multiples of 32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192a379-5b33-4c79-8cd6-6750daad983b",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data#batching_dataset_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80f6ab-882f-4f18-b9df-f64587847ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "ds_train = ds_train.batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a41ab-16a5-4648-88be-39b983f1bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564c94f-85b0-4219-b028-c22e46a40ebf",
   "metadata": {},
   "source": [
    "#### PyTorch (Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcb316-f973-410f-9d89-5336f93a1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769c027-a356-4ba0-ad9c-f98d2e241833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2eacf-66ed-446c-8678-dbf163150778",
   "metadata": {},
   "source": [
    "[Automatic batch size](https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#batch-size-finder) with PyTorch lightning:\n",
    "\n",
    "```python\n",
    "Trainer(auto_scale_batch_size=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d86bf7-26f5-40a1-996b-9fadb6c8cd28",
   "metadata": {},
   "source": [
    "### Map\n",
    "\n",
    "Map a preprocessing function to a dataset.\n",
    "\n",
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data#preprocessing_data)\n",
    "\n",
    "```python\n",
    "dataset.map(function)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98021ef-a4e6-4aa8-a475-98bccc0d59bb",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "There are range of ways to [improve the performance](https://www.tensorflow.org/guide/data_performance) of the data pipeline.\n",
    "\n",
    "In these examples, using `tf.data.AUTOTUNE` leaves the decision to TensorFlow.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5997c7-740e-4537-9324-78bf44945549",
   "metadata": {
    "tags": []
   },
   "source": [
    "(cache_tf)=\n",
    "### Dataset caching\n",
    "\n",
    "Cache the data after the first iteration through it. The data can be cached to either memory or a local file.\n",
    "\n",
    "This can improve performance when:\n",
    "\n",
    "- The data is the same each iteration.\n",
    "- The data is read from a remote distributed filesystem.\n",
    "- The data is I/O (input/output) bound and will fit in memory.\n",
    "\n",
    "Note, large datasets are sharded rather than cached, as they don't fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e60f4-e9e9-4c3b-b11b-d66ead863112",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data_performance#caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87a0a0-e923-4cf6-aa80-b7e9ff65a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fdabd-d894-44fe-af2a-e4723415690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc418c3-02bb-411f-a3e4-66881fd13ff4",
   "metadata": {},
   "source": [
    "(prefetch_tf)=\n",
    "### Prefetch data\n",
    "\n",
    "Overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc444c-b5d1-4dad-af18-43b3afaf8851",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data_performance#prefetching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c26e4d-5d6f-4b9b-bc2f-d4e21f0290e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dac752-9ebd-4050-a458-5f1904ec4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9acb0-d20b-48ab-a204-6473c50931ed",
   "metadata": {},
   "source": [
    "### Parallel data extraction\n",
    "\n",
    "Extract the data in parallel.\n",
    "\n",
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data_performance#parallelizing_data_extraction)\n",
    "\n",
    "```python\n",
    "dataset.interleave(\n",
    "    build_dataset, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb3c83-ca9e-450c-97f7-cf7082a3b781",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch.org/docs/stable/data.html#multi-process-data-loading)\n",
    "\n",
    "Set `num_workers` to be greater than 0 in the DataLoader:\n",
    "\n",
    "```python\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe022f-4de6-41f0-9ad9-3c0e96ea54b1",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Can also pin memory to the GPU for faster memory copies by adding `pin_memory=True` inside the DataLoader.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f5b37-156f-4566-b15f-d0ded20daa83",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "Pre-processing your data is helpful as it is often not the exact format that the model performs well with.\n",
    "\n",
    "For example, normalising the values in a tensor (to have zero-mean and unit-variance or to be between 0 and 1) can help with model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aca83a-059e-47d5-8171-0e0ee4c9aae1",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Pre-processing transformations are based on the training data _only_ (not the test data). For example, if you normalise by the avergage, ensure that this is the average of the training data only.\n",
    "\n",
    "These are then applied to the inputs of both the _training_ and the _test_ data.  \n",
    "\n",
    "This helps avoid [data leakage](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb1d4f-d252-4b20-a738-7a45395fcb15",
   "metadata": {},
   "source": [
    "#### [scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fa156-921b-4157-9501-a97f89b6f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cc82d-1773-4e4f-a721-c9504e11f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.StandardScaler()  # standardisation: zero mean and unit variance\n",
    "preprocessing.Normalizer()  # normalisation: unit norm\n",
    "preprocessing.PowerTransformer()  # mapping to Gaussian distribution\n",
    "preprocessing.OneHotEncoder()  # encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46053322-e513-4841-a861-4134253cdb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe7996ef-3c84-4114-8989-57ceacd8eb86",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/keras/preprocessing_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500d3e2-2465-4f6d-98ae-6d5e8022222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Rescaling(1.0 / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040654e-e721-460c-a686-f771d50e24d5",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42349a45-248c-4e8f-8dc7-1433ae0b8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3495d7-915e-4d14-a46f-47921694563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Normalize((0.1307,), (0.3081,)),  # specific to MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1190d-741b-4254-afa7-2a20bba38416",
   "metadata": {},
   "source": [
    "(data_augmentation)=\n",
    "### [Data augmentation](https://youtu.be/JI8saFjK84o)\n",
    "\n",
    "Artificially increasing the range and number of training examples.\n",
    "\n",
    "Useful for small data sets.\n",
    "\n",
    "There are a range of methods. For example, in image problems you could rotate, stretch, and reflect images.\n",
    "\n",
    "Note, apply random transformations _after_ both caching (to avoid caching randomness) and batching (for vectorisation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962649a5-79c6-4021-ab86-c9622d65a64e",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/tutorials/images/data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb9b70-da41-49d2-a573-f3c0a796b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.RandomFlip(\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cf5e7-a901-4a70-bef3-45daa4c19996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.RandomRotation(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd9d6e-66ca-4f57-87d9-5ae50c2f0fbc",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch.org/vision/master/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70186efe-f379-4128-a9f6-f405cd646a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.RandomHorizontalFlip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cf26d-8eaf-491d-bc31-2fbe9e345b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.RandomRotation(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c41aa-b850-46a3-a910-27dce98146ce",
   "metadata": {},
   "source": [
    "###  Parallel data transformation\n",
    "\n",
    "Pre-process your data in parallel.\n",
    "\n",
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data_performance#parallelizing_data_transformation)\n",
    "\n",
    "```python\n",
    "dataset.map(\n",
    "    function, \n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e2947-d742-49be-a778-6f55709063c1",
   "metadata": {},
   "source": [
    "### Vectorise mapping\n",
    "\n",
    "Batch _before_ mapping, to vectorise a function.\n",
    "\n",
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/data_performance#vectorizing_mapping)\n",
    "\n",
    "```python\n",
    "dataset.batch(256).map(function)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcdda9-ca76-4782-9b72-eef878aedd89",
   "metadata": {},
   "source": [
    "### Mixed precision\n",
    "\n",
    "Mixed precision is the use of 16-bit and 32-bit floating-point types during training to use less memory and make it run faster.\n",
    "\n",
    "It uses 32-bits where it needs to for accuracy and 16-bits elsewhere for speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de358df-016c-4cb7-8765-182c67907b8e",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This functionality varies by GPU, and is mostly available to modern NVIDIA GPUs.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d962911-8fcc-4c70-bfb0-4f7b57d27d89",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Be careful with underflow and overflow issues.\n",
    "\n",
    "16-bit floats above 65504 overflow to infinity and below 6.0<sub>x10</sub><sup>-8</sup> underflow to zero.\n",
    "\n",
    "[Loss scaling](https://www.tensorflow.org/guide/mixed_precision#loss_scaling_overview) can help avoid errors by scaling the losses up or down temporarily i.e.,:  \n",
    "`optimizer = mixed_precision.LossScaleOptimizer(optimizer)`  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a344e-a196-4a82-b2c9-7decbf252e33",
   "metadata": {},
   "source": [
    "#### [TensorFlow (Keras)](https://www.tensorflow.org/guide/mixed_precision)\n",
    "\n",
    "```python\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012030de-5c05-401c-8c01-82b367d07666",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch-lightning.readthedocs.io/en/stable/advanced/precision.html#)\n",
    "\n",
    "```python\n",
    "Trainer(precision=16)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e972709-298c-4d40-9e17-434f7508b4f0",
   "metadata": {},
   "source": [
    "### Example - Digit Classification\n",
    "\n",
    "(tensorflow_datasets)=\n",
    "#### [TensorFlow Datasets](https://www.tensorflow.org/datasets)\n",
    "\n",
    "A collection of datasets ready to use, with TensorFlow or other Python ML frameworks.\n",
    "\n",
    "Here is an example for [MNIST](https://www.tensorflow.org/datasets/keras_example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66faad38-5728-4c18-b25a-e226ca62c5d9",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63969a2-8c4d-4df3-a22e-58a96c8d6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
    "    shuffle_files=True,  # good practise for larger datasets with many files on disk\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e067c-3409-495e-a5d3-37f9a7a9fc38",
   "metadata": {},
   "source": [
    "Create the data pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde77b2c-4a74-4ffe-ab73-f426af501a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def normalise_image(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "def training_pipeline(ds_train):\n",
    "    ds_train = ds_train.map(\n",
    "        normalise_image, num_parallel_calls=AUTOTUNE\n",
    "    )  # parallelise preprocessing first to reuse it\n",
    "    ds_train = ds_train.cache()  # cache before shuffling for performance\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits[\"train\"].num_examples\n",
    "    )  # shuffle by the full dataset size\n",
    "    ds_train = ds_train.batch(\n",
    "        128\n",
    "    )  # batch after shuffling for unique batches at each epoch\n",
    "    ds_train = ds_train.prefetch(\n",
    "        AUTOTUNE\n",
    "    )  # end pipeline with prefetching for performance\n",
    "    return ds_train\n",
    "\n",
    "\n",
    "def test_pipeline(ds_test):\n",
    "    ds_test = ds_test.map(normalise_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    # cache after batching because batches can be the same between epochs\n",
    "    # no shuffling needed\n",
    "    ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "    return ds_test\n",
    "\n",
    "\n",
    "ds_train = training_pipeline(ds_train)\n",
    "ds_val = training_pipeline(ds_val)\n",
    "ds_test = test_pipeline(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b47c0-341f-45ff-94bd-f2102acbfc33",
   "metadata": {},
   "source": [
    "Create the model using the [Functional API](https://keras.io/guides/functional_api/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a271baf-ed45-46cf-b78c-2940b498816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"functional\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac78f67-725c-49fc-bd90-dd9e0e23588d",
   "metadata": {},
   "source": [
    "Compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ea3e6-9fb3-46a3-9d72-c94e613fc965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc74fc-77db-4fa7-a776-37910142120d",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebf32d-a425-45ab-b014-4b34ef243939",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=False,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c1f87-d04f-4d11-8608-743e6b71ccb3",
   "metadata": {},
   "source": [
    "View the loss and accuracy curves over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472d984-cade-4aaa-b359-f51c4aee782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, NUM_EPOCHS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa84ee-a7c8-4fee-b768-7d34d796398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_range, history.history[\"loss\"], \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs_range, history.history[\"val_loss\"], \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a14d10-fa6f-4c49-882a-1580c89502b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_range, history.history[\"accuracy\"], \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(\n",
    "    epochs_range, history.history[\"val_accuracy\"], \"b\", label=\"Validation accuracy\"\n",
    ")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0.9, 1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8b845-c6f7-4d30-99dd-d4c90ad344a2",
   "metadata": {},
   "source": [
    "The training accuracy and the validation accuracy are diverging.\n",
    "\n",
    "The model is overfitting (i.e., doing too well on the training data compared to the validation data).\n",
    "\n",
    "One way to alleviate this is to [add weight regularisation](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#add_weight_regularization).\n",
    "\n",
    "In this example, we'll add [dropout](overfit) to the dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4d8ae-9abc-42c3-860f-972ebbe6613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1), name=\"inputs\")\n",
    "x = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer1\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # I'm new\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\", name=\"layer2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, name=\"outputs\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"functional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbed15-d6f0-425c-b4d3-78222728f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f2c01-d546-4793-97b9-4324ebd831c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=False,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1dbd7d-0192-47ba-884a-981bdc500f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_range, history.history[\"accuracy\"], \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(\n",
    "    epochs_range, history.history[\"val_accuracy\"], \"b\", label=\"Validation accuracy\"\n",
    ")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0.9, 1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2820c94-9d6e-4cfb-8611-5ea60fbede77",
   "metadata": {},
   "source": [
    "#### [PyTorch (Lightning)](https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/datamodules.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8f748-4001-4e1b-9206-b0ccfd260eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import (\n",
    "    LightningDataModule,\n",
    "    LightningModule,\n",
    "    Trainer,\n",
    "    seed_everything,\n",
    ")\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216249e-b20b-400a-9818-54663e2b416e",
   "metadata": {},
   "source": [
    "Set global parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94766dd6-d3a6-4ae0-83a6-323c689f5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266281a-d469-4ad5-a0e6-535e694c1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = f\"{os.getcwd()}/data\"\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00dc4f-12d5-4b05-898f-57896bb7bf67",
   "metadata": {},
   "source": [
    "[Create the (dataset agnostic) PyTorch Lightning Model](https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/datamodules.html#Defining-the-dataset-agnostic-LitModel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12b30a-42d2-4320-9aba-817ebda3154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(LightningModule):\n",
    "    def __init__(\n",
    "        self, channels, width, height, num_classes, hidden_size=64, learning_rate=2e-4\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We take in input dimensions as parameters and use those to dynamically build model.\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d7e97-f260-41e4-ba9e-6420aadd6f6c",
   "metadata": {},
   "source": [
    "[Create the PyTorch Lightning DataModule](https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/datamodules.html#Defining-The-MNISTDataModule):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75132f-f967-4b99-973c-3b581c056195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),  # specific to MNIST\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):  # download the data, once if distributed\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(\n",
    "                self.data_dir, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa86a56-9ed1-4710-bc2a-6a4765e1041f",
   "metadata": {},
   "source": [
    "Instantiate the Model, DataModule, and Trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a5053-75c8-4b38-9f7c-2150732f79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MNISTDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ccfb5-dc97-4ccc-9716-a1242e4da29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(channels=1, width=28, height=28, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efcc15-1e2a-4097-88ba-7e6127b2f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    callbacks=TQDMProgressBar(refresh_rate=20),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19317f2-047f-4136-9caf-51896d52822c",
   "metadata": {},
   "source": [
    "Run training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4f55a-132c-458e-b436-54b6bbe1f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65a9d8-ddf4-4601-89d9-47fce4b7e2be",
   "metadata": {},
   "source": [
    "Test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220adfd-89e1-4b6d-9c47-1754cf222688",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19bc0e-c62d-4251-8633-03b4438afa13",
   "metadata": {},
   "source": [
    "Now, could [change over to a different dataset](https://pytorchlightning.github.io/lightning-tutorials/notebooks/lightning_examples/datamodules.html#Defining-the-CIFAR10-DataModule) e.g., [CIFAR10](https://en.wikipedia.org/wiki/CIFAR-10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0a6fb-a1e1-4dd1-8219-9682dbf076cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "                ),  # specific to CIFAR10\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):  # download the data, once if distributed\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.cifar_test = CIFAR10(\n",
    "                self.data_dir, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966e0fd-ddec-4888-88d0-133ef368ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CIFAR10DataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1b26b-0dda-43ac-a6b6-d39018bff2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(channels=3, width=32, height=32, num_classes=10, hidden_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb36ffa-3838-4601-8d5d-8a541cdf64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    callbacks=TQDMProgressBar(refresh_rate=20),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d70fa-1564-41d0-b4ba-5662046b42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87a945-535b-4041-b4d4-b520ae971bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e34c0d-a6c6-4454-bfc3-4d332abbd9da",
   "metadata": {},
   "source": [
    "This simple model works well for MNIST but not for CIFAR10. However, it demonstrates the ease and benefits of switching out data modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced90880-2461-4db1-b19f-3c80eb1f48e9",
   "metadata": {},
   "source": [
    "[PyTorch Lightning Bolts](https://lightning-bolts.readthedocs.io/en/latest/introduction_guide.html) simplifies this for common [DataModules](https://lightning-bolts.readthedocs.io/en/latest/datamodules/vision.html) (e.g., MNIST, FashionMNIST, CIFAR10, ImageNet) by providing them for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495bcdb-f8b7-4139-bba4-b708ec5028ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa242b-97f0-4d06-8fd5-a3e06399cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = MNISTDataModule(PATH_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33d5c7-9a9a-484f-b0c2-5d0c828c77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(channels=1, width=28, height=28, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bcbe4-58a6-45df-87f0-9fe916c85e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    callbacks=TQDMProgressBar(refresh_rate=20),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b58b1d-89d8-4f39-80f0-c392fc4b9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b93c1-d16b-417e-9e37-07e5ee57248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d97e31-d585-4eef-9a73-439e96d7db21",
   "metadata": {},
   "source": [
    "PyTorch Lighting Bolts also has a range of models (e.g., regression, GPT-2, ImageGPT, GAN, VAE):\n",
    "\n",
    "```python\n",
    "from pl_bolts.models.vision import ImageGPT\n",
    "```\n",
    "\n",
    "Also, you can [easily override functionality for fast iteration of research ideas](https://lightning-bolts.readthedocs.io/en/latest/introduction_guide.html#for-research)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <data>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _Always split the data into train and test subsets first, before any pre-processing._\n",
    "- [x] _Never fit to the test data._\n",
    "- [x] _Use a data pipeline._\n",
    "- [x] _Use a random seed and any available deterministic functionalities for reproducibility._\n",
    "    - [x] _Try and reproduce your own work, to check that it is reproducible._\n",
    "- [x] _Optimise the data pipeline with:_\n",
    "    - [x] _Caching._\n",
    "    - [x] _Prefetching._\n",
    "    - [x] _Parallel extraction._\n",
    "    - [x] _Parallel preprocessing._\n",
    "    - [x] _Vectorised mapping._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Do data processing as part of the model to increase portability and reproducibility.\n",
    "- Pre-processing transformations are based on the training data _only_ (not the test data). These are then applied to the inputs of both the _training_ and the _test_ data.\n",
    "- Analyse data pipeline performance with [TensorBoard Profiler](https://www.tensorflow.org/guide/data_performance_analysis).\n",
    "- Use sparse tensors when there are many zeros / np.nans (e.g., [TensorFlow](https://www.tensorflow.org/guide/sparse_tensor)).\n",
    "- Take care with [datasets with imbalanced classes](https://developers.google.com/machine-learning/glossary/#class-imbalanced-dataset) (i.e., only a few positive samples).\n",
    "- Take care to avoid [data leakage](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage) (i.e., never fit to the test data).\n",
    "- Best practices for [managing data with PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/stable/guides/data.html) and [scikit-learn](https://scikit-learn.org/stable/common_pitfalls.html).\n",
    "- Models are often heavily optimised, while the data is less so. There are many good practices around [data-centric machine learning](https://datacentricai.org/).\n",
    "- Consider sharing your data for reproducibility if you can.\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [NVIDIA Data Loading Library (DALI)](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html)\n",
    "    - A library for data loading and pre-processing to accelerate deep learning applications.\n",
    "- [Ray Datasets](https://docs.ray.io/en/latest/data/dataset.html)\n",
    "    - Load and exchange data in Ray libraries and applications. \n",
    "- [NVIDIA Replicator Composer](https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/tutorial_replicator_composer.html#replicator-composer)\n",
    "    - A tool for creating synthetic data.\n",
    " \n",
    "### Resources\n",
    "\n",
    "- [Papers with code - Datasets](https://paperswithcode.com/datasets)\n",
    "- [HuggingFace - Datasets](https://huggingface.co/datasets)\n",
    "- [Google research datasets](https://ai.google/tools/datasets/)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com/)\n",
    "- [Google Cloud public datasets](https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset&pli=1)\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
    "- [Torch Vision Datasets](https://pytorch.org/vision/stable/datasets.html)\n",
    "- [Torch Text Datasets](https://pytorch.org/text/stable/datasets.html)\n",
    "- [Torch Audio Datasets](https://pytorch.org/audio/stable/datasets.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "swd8_intro_ml",
   "language": "python",
   "name": "swd8_intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
