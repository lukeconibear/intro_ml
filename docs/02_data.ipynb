{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f167c0-52a8-4800-9999-0419acc312a8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8044-47c9-4c48-b50d-e3dadb441757",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lukeconibear/intro_ml/blob/main/docs/02_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aef6fc-d7fe-45a5-9593-f9092ae02ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're using colab, then install the required modules\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dfa3b88-94b6-48bb-ba42-13c73c737b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa8feb67-51a9-419e-bd16-7e8400101b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60170661])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3d9ce0f-03a6-4abe-9588-d188a3c67ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.9826471], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "831462f9-b995-4e5b-b2c4-c9471a314c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.85227818, -0.01349722, -1.05771093])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e33b808-fa98-49c1-9430-04b400afe954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.7847413, -0.5809721, -0.2452356], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0777c90d-53bd-43ee-9ee0-538f14d3f53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82254491, -1.22084365,  0.2088636 ],\n",
       "       [-1.95967012, -1.32818605,  0.19686124],\n",
       "       [ 0.73846658,  0.17136828, -0.11564828]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6b0ddf4-2bbf-4271-8023-fe861458b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 1.2764754 , -0.6551445 , -0.00389835],\n",
       "       [ 0.45862213, -1.507044  ,  1.0932531 ],\n",
       "       [-0.45938343, -0.35318485, -0.3738681 ]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab75ca-1fe0-42db-aff4-a7ce600b49c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d697c977-166e-4cb9-a382-999d436eafad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4d42d-9f38-4640-9210-6850442f9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33dc9f84-c149-4142-b6d4-68616b19f312",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Keras models accept three types of inputs:\n",
    "\n",
    "- NumPy arrays, just like Scikit-Learn and many other Python-based libraries. This is a good option if your data fits in memory.\n",
    "- TensorFlow Dataset objects. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n",
    "- Python generators that yield batches of data (such as custom subclasses of the keras.utils.Sequence class).\n",
    "\n",
    "\n",
    "If you have a large dataset and you are training on GPU(s), consider using `Dataset` objects, since they will take care of performance-critical details, such as:\n",
    "\n",
    "- Asynchronously preprocessing your data on CPU while your GPU is busy, and buffering it into a queue.\n",
    "- Prefetching data on GPU memory so it's immediately available when the GPU has finished processing the previous batch, so you can reach full GPU utilization.\n",
    "\n",
    "Keras features a range of utilities to help you turn raw data on disk into a Dataset:\n",
    "\n",
    "- [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) turns image files sorted into class-specific folders into a labeled dataset of image tensors.\n",
    "- [`tf.keras.utils.text_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory) does the same for text files.\n",
    "- [`tf.keras.utils.timeseries_dataset_from_array`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array) creates a dataset of sliding windows over a timeseries provided as array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c69061-254f-4440-9f6a-aa7e8cbae26f",
   "metadata": {},
   "source": [
    "\"step fusing\"\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimiser,\n",
    "    loss,\n",
    "    steps_per_execution=32  # this step\n",
    ")\n",
    "model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a1720-77d5-4d44-973b-60dd2c2a1da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2515bb-2d97-4621-b6f6-ae3586969ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fef8cd7e-1841-45e6-85b0-494ada8c881b",
   "metadata": {},
   "source": [
    "jit compile\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimiser,\n",
    "    loss,\n",
    "    jit_compile=True  # this step\n",
    ")\n",
    "model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c2c5d-11cc-47c3-895d-ad82b8c3f940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd2169-abea-4ee2-899e-e26fcbf91e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ec18c1-3dad-4d18-9830-55acd84397e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "- Tokenization of string data, followed by token indexing.\n",
    "- Feature normalization.\n",
    "- Rescaling the data to small values (in general, input values to a neural network should be close to zero -- typically we expect either data with zero-mean and unit-variance, or data in the [0, 1] range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17d4f1-a78a-42cb-9630-3d5f0dd7a6ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0da989-7664-49f9-9b5e-f9321fb81670",
   "metadata": {},
   "source": [
    "## Mixed precision\n",
    "\n",
    "...\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_policy('mixed_float16')\n",
    "\n",
    "with distribution_strategy.scopy():\n",
    "    model = build_model()\n",
    "    model.compile(optimiser, loss)\n",
    "    model.fit(dataset, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ee263-d591-4417-8c86-5b26a843b2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72ea9e50-8cd8-4b1e-b1a9-a6c84588fc76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2d7db6-9738-4a79-b501-955e520f2118",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64f1798-eb46-4759-b023-8dd649f74c40",
   "metadata": {},
   "source": [
    "- datasets\n",
    "- data centric AI hub videos\n",
    "- efficient feeding of data into GPUs\n",
    "- pipelines for large data I/O into GPUs using compression/decompression, Ray datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b9649-dfb3-4d66-bdb7-a565a9bdc3be",
   "metadata": {},
   "source": [
    "### Synthetic data\n",
    "\n",
    "...\n",
    "\n",
    "- [NVIDIA Replicator Composer](https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/tutorial_replicator_composer.html#replicator-composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c515783-b33e-448b-8b7d-2a264dd5bdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f47a8-9ad1-4dba-8577-c5b394ee3b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f13dcc-ae37-4518-8ff1-fad3c30dc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1390c-7a87-4fe8-a640-58b0164bd58a",
   "metadata": {},
   "source": [
    "Check whether you have a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0de7f-6c5e-4272-b109-bac76ecd0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"Yes, there are {len(tf.config.list_physical_devices('GPU'))} GPUs available.\")\n",
    "else:\n",
    "    print('No, GPUs are not available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34152b35-1cbe-4b3d-96f0-f5a47f523c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a7146e-bc2d-4078-b65e-b6b983d588e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74e521-e75b-4684-a8b3-b01951a40340",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8af3b-5d9a-4e2c-9bd0-223837749e07",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <data>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85d337-9ea3-4511-ae33-4fb036418318",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de920e-c4c1-4c47-8a80-b7f1ab648754",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _..._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bcbb5-e4c3-4032-b7af-8fd24d9e19e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practices\n",
    "\n",
    "- Do data processing as part of the model to increase portability and reproducibility.\n",
    "- ...\n",
    "\n",
    "### Other options\n",
    "\n",
    "- ...\n",
    " \n",
    "### Resources\n",
    "\n",
    "#### General\n",
    "\n",
    "- [Papers with code - Datasets](https://paperswithcode.com/datasets)\n",
    "- [HuggingFace - Datasets](https://huggingface.co/datasets)\n",
    "- [Google research datasets](https://ai.google/tools/datasets/)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com/)\n",
    "- [Google Cloud public datasets](https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset&pli=1)\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
    "\n",
    "#### TensorFlow\n",
    "\n",
    "- [TensorFlow official datasets](https://www.tensorflow.org/datasets)\n",
    "\n",
    "#### PyTorch\n",
    "\n",
    "- [Torch Vision Datasets](https://pytorch.org/vision/stable/datasets.html)\n",
    "- [Torch Text Datasets](https://pytorch.org/text/stable/datasets.html)\n",
    "- [Torch Audio Datasets](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c3e08-05b5-431f-b842-82ffe49b99c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "intro_ml",
   "language": "python",
   "name": "intro_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
